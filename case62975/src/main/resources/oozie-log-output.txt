SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/data/2/yarn/nm/filecache/7535/rtb-oozie-spark-deploy-1.0.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory]
1035 [main] INFO org.apache.hadoop.metrics2.impl.MetricsConfig - loaded properties from hadoop-metrics2.properties
1185 [main] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled snapshot period at 10 second(s).
1185 [main] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - MapTask metrics system started
1202 [main] INFO org.apache.hadoop.mapred.YarnChild - Executing with tokens:
1271 [main] INFO org.apache.hadoop.mapred.YarnChild - Kind: mapreduce.job, Service: job_1433901314076_29226, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@7703a25d)
1271 [main] INFO org.apache.hadoop.mapred.YarnChild - Kind: RM_DELEGATION_TOKEN, Service: 10.12.12.23:8032,10.12.12.51:8032, Ident: (owner=rtb-system, renewer=oozie mr token, realUser=oozie, issueDate=1434121738634, maxDate=1434726538634, sequenceNumber=507255, masterKeyId=169)
1345 [main] INFO org.apache.hadoop.mapred.YarnChild - Sleeping for 0ms before retrying again. Got null now.
1777 [main] INFO org.apache.hadoop.mapred.YarnChild - mapreduce.cluster.local.dir for child: /data/1/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/2/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/3/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/4/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/5/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/6/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/7/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226,/mapred/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226
2562 [main] INFO org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
3314 [main] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
3328 [main] INFO org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
3878 [main] INFO org.apache.hadoop.mapred.MapTask - Processing split: org.apache.oozie.action.hadoop.OozieLauncherInputFormat$EmptySplit@ce5af8b
3890 [main] INFO org.apache.hadoop.mapred.MapTask - numReduceTasks: 0
3985 [main] INFO org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
Using properties file: null
Parsed arguments:
  master                  yarn-client
  deployMode              client
  executorMemory          null
  executorCores           null
  totalExecutorCores      null
  propertiesFile          null
  driverMemory            null
  driverCores             null
  driverExtraClassPath    null
  driverExtraLibraryPath  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
  driverExtraJavaOptions  null
  supervise               false
  queue                   null
  numExecutors            3
  files                   null
  pyFiles                 null
  archives                null
  mainClass               com.dealertrack.advertising.rtb.job.ViewBatchJob
  primaryResource         hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar
  name                    ViewThroughCorrelationJob
  childArgs               [-n RTBViewThroughCorrelation --kryoClasses com.dealer.analytics.ad.intake.RTBEnrichedImpression,com.dealer.analytics.pixall.intake.PixAllHit,com.dealer.analytics.ad.intake.RTBImpression --properties mutableOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16,permOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16,viewsFile=hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16,summarizeTimeUnit=hour,mutableWindowStart=2015-05-12T16:00:00 --impressionFiles hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16]
  jars                    null
  packages                null
  repositories            null
  verbose                 true

Spark properties used, including those specified through
 --conf and those from the properties file null:
  spark.executor.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
  spark.yarn.jar -> local:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/spark/assembly/lib/spark-assembly-1.3.0-cdh5.4.1-hadoop2.6.0-cdh5.4.1.jar
  spark.driver.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
  spark.yarn.am.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
  spark.yarn.historyServer.address -> http://vtqaana-cloudera01.dealer.ddc:18088
  spark.eventLog.enabled -> true
  spark.serializer -> org.apache.spark.serializer.KryoSerializer
  spark.shuffle.service.enabled -> true
  spark.shuffle.service.port -> 7337
  spark.eventLog.dir -> hdfs://nameservice1/user/spark/applicationHistory
  spark.master -> yarn-client


Main class:
com.dealertrack.advertising.rtb.job.ViewBatchJob
Arguments:
-n
RTBViewThroughCorrelation
--kryoClasses
com.dealer.analytics.ad.intake.RTBEnrichedImpression,com.dealer.analytics.pixall.intake.PixAllHit,com.dealer.analytics.ad.intake.RTBImpression
--properties
mutableOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16,permOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16,viewsFile=hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16,summarizeTimeUnit=hour,mutableWindowStart=2015-05-12T16:00:00
--impressionFiles
hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16
System properties:
spark.executor.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
spark.yarn.jar -> local:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/spark/assembly/lib/spark-assembly-1.3.0-cdh5.4.1-hadoop2.6.0-cdh5.4.1.jar
spark.driver.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
spark.executor.instances -> 3
spark.yarn.am.extraLibraryPath -> /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
spark.yarn.historyServer.address -> http://vtqaana-cloudera01.dealer.ddc:18088
spark.eventLog.enabled -> true
SPARK_SUBMIT -> true
spark.serializer -> org.apache.spark.serializer.KryoSerializer
spark.app.name -> ViewThroughCorrelationJob
spark.shuffle.service.enabled -> true
spark.jars -> hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar
spark.shuffle.service.port -> 7337
spark.eventLog.dir -> hdfs://nameservice1/user/spark/applicationHistory
spark.master -> yarn-client
Classpath elements:
hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar


Warning: Skip remote jar hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar.
5725 [main] INFO com.dealertrack.advertising.rtb.job.ViewBatchJob$ - Running with config ViewCommandLine(local[2],RTBViewThroughCorrelation,ArraySeq(com.dealer.analytics.ad.intake.RTBEnrichedImpression, com.dealer.analytics.pixall.intake.PixAllHit, com.dealer.analytics.ad.intake.RTBImpression),Map(),Map(mutableOutputFileName -> hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16, permOutputFileName -> hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16, summarizeTimeUnit -> hour, mutableWindowStart -> 2015-05-12T16:00:00, viewsFile -> hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16),ArraySeq(hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16))
6133 [main] INFO org.apache.spark.SparkContext - Running Spark version 1.3.0
6206 [main] INFO org.apache.spark.SecurityManager - Changing view acls to: yarn,rtb-system
6207 [main] INFO org.apache.spark.SecurityManager - Changing modify acls to: yarn,rtb-system
6208 [main] INFO org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, rtb-system); users with modify permissions: Set(yarn, rtb-system)
7069 [sparkDriver-akka.actor.default-dispatcher-4] INFO akka.event.slf4j.Slf4jLogger - Slf4jLogger started
7119 [sparkDriver-akka.actor.default-dispatcher-4] INFO Remoting - Starting remoting
7342 [sparkDriver-akka.actor.default-dispatcher-2] INFO Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@vtqaana-cloudera01.dealer.ddc:36312]
7344 [sparkDriver-akka.actor.default-dispatcher-4] INFO Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@vtqaana-cloudera01.dealer.ddc:36312]
7354 [main] INFO org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 36312.
7378 [main] INFO org.apache.spark.SparkEnv - Registering MapOutputTracker
7400 [main] INFO org.apache.spark.SparkEnv - Registering BlockManagerMaster
7425 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/1/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-5f635a87-7846-4156-9a40-3b83a20698f1
7425 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/2/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-44f371be-3181-48ed-b82b-ce45d1b78ccf
7425 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/3/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-bf82bee7-908f-4639-9746-6b1cd25a578a
7426 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/4/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-2e332fb1-0624-4616-a77a-6f596af19e79
7426 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/5/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-1b2580e4-50c9-44ba-aa58-fffe34e18a26
7426 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/6/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-a6e6d33c-7506-4f9d-b8a7-1aa6fe5e900a
7427 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/7/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-d57fe0e0-b089-4d8e-bdfb-8f6817870805
7428 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-21503c53-c25e-4780-953f-e77f26f57ea7
7428 [main] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /mapred/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/blockmgr-10e11d93-0308-4844-abb2-15f9fb04f57e
7439 [main] INFO org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 794.9 MB
7555 [main] INFO org.apache.spark.HttpFileServer - HTTP File server directory is /data/1/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/httpd-abebf552-c49b-414b-bd85-82020cddd283
7568 [main] INFO org.apache.spark.HttpServer - Starting HTTP Server
7663 [main] INFO org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
7693 [main] INFO org.spark-project.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:48295
7693 [main] INFO org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 48295.
7717 [main] INFO org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
7917 [main] INFO org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
7929 [main] WARN org.spark-project.jetty.util.component.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:207)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:217)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:217)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1832)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1823)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:217)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:307)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:307)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:307)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch$$anonfun$main$1.apply(DtSparkBatch.scala:52)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch$$anonfun$main$1.apply(DtSparkBatch.scala:43)
	at scala.Option.foreach(Option.scala:236)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch.main(DtSparkBatch.scala:43)
	at com.dealertrack.advertising.rtb.job.ViewBatchJob.main(ViewThroughCorrelation.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	at org.apache.oozie.action.hadoop.SparkMain.runSpark(SparkMain.java:105)
	at org.apache.oozie.action.hadoop.SparkMain.run(SparkMain.java:96)
	at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:46)
	at org.apache.oozie.action.hadoop.SparkMain.main(SparkMain.java:40)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:228)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
7931 [main] WARN org.spark-project.jetty.util.component.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@1fd2849: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:207)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:217)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:217)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1832)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1823)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:217)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:307)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:307)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:307)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch$$anonfun$main$1.apply(DtSparkBatch.scala:52)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch$$anonfun$main$1.apply(DtSparkBatch.scala:43)
	at scala.Option.foreach(Option.scala:236)
	at com.dealertrack.analytics.spark.batch.DtSparkBatch.main(DtSparkBatch.scala:43)
	at com.dealertrack.advertising.rtb.job.ViewBatchJob.main(ViewThroughCorrelation.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	at org.apache.oozie.action.hadoop.SparkMain.runSpark(SparkMain.java:105)
	at org.apache.oozie.action.hadoop.SparkMain.run(SparkMain.java:96)
	at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:46)
	at org.apache.oozie.action.hadoop.SparkMain.main(SparkMain.java:40)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:228)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
7935 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
7935 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
7935 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
7935 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
7936 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
7937 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
7938 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
7938 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
7938 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
7938 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
7938 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
7993 [main] WARN org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
7994 [main] INFO org.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
8014 [main] INFO org.spark-project.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4041
8014 [main] INFO org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4041.
8016 [main] INFO org.apache.spark.ui.SparkUI - Started SparkUI at http://vtqaana-cloudera01.dealer.ddc:4041
8065 [main] INFO org.apache.spark.SparkContext - Added JAR hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar at hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar with timestamp 1434121754185
8136 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.executor.Executor - Starting executor ID <driver> on host localhost
8151 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@vtqaana-cloudera01.dealer.ddc:36312/user/HeartbeatReceiver
8363 [main] INFO org.apache.spark.network.netty.NettyBlockTransferService - Server created on 60336
8366 [main] INFO org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
8368 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManagerMasterActor - Registering block manager localhost:60336 with 794.9 MB RAM, BlockManagerId(<driver>, localhost, 60336)
8371 [main] INFO org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
8705 [main] INFO org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://nameservice1/user/spark/applicationHistory/local-1434121754229
8978 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(920) called with curMem=0, maxMem=833492090
8980 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 920.0 B, free 794.9 MB)
9273 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(243) called with curMem=920, maxMem=833492090
9273 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 243.0 B, free 794.9 MB)
9276 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60336 (size: 243.0 B, free: 794.9 MB)
9277 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_0_piece0
9284 [main] INFO org.apache.spark.SparkContext - Created broadcast 0 from broadcast at ViewThroughCorrelation.scala:54
9286 [main] INFO com.dealertrack.advertising.rtb.job.ViewBatchJob$ - Loading clicks file: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16
9397 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=1163, maxMem=833492090
9398 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 315.1 KB, free 794.6 MB)
9487 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23590) called with curMem=323856, maxMem=833492090
9488 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.0 KB, free 794.5 MB)
9489 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.9 MB)
9489 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_1_piece0
9492 [main] INFO org.apache.spark.SparkContext - Created broadcast 1 from newAPIHadoopFile at ViewThroughCorrelation.scala:57
9533 [main] INFO com.dealertrack.advertising.rtb.job.ViewBatchJob$ - Loading impressions file: ArraySeq(hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17, hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16)
9599 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=347446, maxMem=833492090
9605 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 315.1 KB, free 794.2 MB)
9691 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23600) called with curMem=670139, maxMem=833492090
9692 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.0 KB, free 794.2 MB)
9693 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.8 MB)
9694 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_2_piece0
9696 [main] INFO org.apache.spark.SparkContext - Created broadcast 2 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
9750 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=693739, maxMem=833492090
9751 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 315.1 KB, free 793.9 MB)
9836 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23597) called with curMem=1016432, maxMem=833492090
9836 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.0 KB, free 793.9 MB)
9838 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.8 MB)
9838 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_3_piece0
9840 [main] INFO org.apache.spark.SparkContext - Created broadcast 3 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
9885 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=1040029, maxMem=833492090
9886 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 315.1 KB, free 793.6 MB)
9950 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=1362722, maxMem=833492090
9951 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.0 KB, free 793.6 MB)
9952 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.8 MB)
9952 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_4_piece0
9954 [main] INFO org.apache.spark.SparkContext - Created broadcast 4 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
9990 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=1386317, maxMem=833492090
9991 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 315.1 KB, free 793.3 MB)
10049 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=1709010, maxMem=833492090
10049 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.0 KB, free 793.2 MB)
10051 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.8 MB)
10051 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_5_piece0
10052 [main] INFO org.apache.spark.SparkContext - Created broadcast 5 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10079 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=1732605, maxMem=833492090
10079 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 315.1 KB, free 792.9 MB)
10139 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23598) called with curMem=2055298, maxMem=833492090
10140 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.0 KB, free 792.9 MB)
10141 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.7 MB)
10141 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_6_piece0
10143 [main] INFO org.apache.spark.SparkContext - Created broadcast 6 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10161 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=2078896, maxMem=833492090
10161 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 315.1 KB, free 792.6 MB)
10240 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=2401589, maxMem=833492090
10240 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.0 KB, free 792.6 MB)
10242 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.7 MB)
10242 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_7_piece0
10243 [main] INFO org.apache.spark.SparkContext - Created broadcast 7 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10261 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=2425184, maxMem=833492090
10261 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 315.1 KB, free 792.3 MB)
10322 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=2747877, maxMem=833492090
10322 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.0 KB, free 792.2 MB)
10324 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.7 MB)
10324 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_8_piece0
10326 [main] INFO org.apache.spark.SparkContext - Created broadcast 8 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10344 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=2771472, maxMem=833492090
10345 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 315.1 KB, free 791.9 MB)
10402 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23597) called with curMem=3094165, maxMem=833492090
10402 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.0 KB, free 791.9 MB)
10404 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.7 MB)
10404 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_9_piece0
10405 [main] INFO org.apache.spark.SparkContext - Created broadcast 9 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10418 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=3117762, maxMem=833492090
10419 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 315.1 KB, free 791.6 MB)
10462 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23600) called with curMem=3440455, maxMem=833492090
10462 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.0 KB, free 791.6 MB)
10464 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.7 MB)
10464 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_10_piece0
10465 [main] INFO org.apache.spark.SparkContext - Created broadcast 10 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10474 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=3464055, maxMem=833492090
10475 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 315.1 KB, free 791.3 MB)
10526 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=3786748, maxMem=833492090
10527 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.0 KB, free 791.2 MB)
10529 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.6 MB)
10529 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_11_piece0
10530 [main] INFO org.apache.spark.SparkContext - Created broadcast 11 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10543 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=3810343, maxMem=833492090
10543 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 315.1 KB, free 790.9 MB)
10693 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23600) called with curMem=4133036, maxMem=833492090
10693 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.0 KB, free 790.9 MB)
10695 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.6 MB)
10695 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_12_piece0
10697 [main] INFO org.apache.spark.SparkContext - Created broadcast 12 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10710 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=4156636, maxMem=833492090
10710 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 315.1 KB, free 790.6 MB)
10775 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23597) called with curMem=4479329, maxMem=833492090
10776 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.0 KB, free 790.6 MB)
10778 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.6 MB)
10779 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_13_piece0
10780 [main] INFO org.apache.spark.SparkContext - Created broadcast 13 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10799 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=4502926, maxMem=833492090
10800 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 315.1 KB, free 790.3 MB)
10868 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23598) called with curMem=4825619, maxMem=833492090
10868 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.0 KB, free 790.3 MB)
10870 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.6 MB)
10880 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_14_piece0
10881 [main] INFO org.apache.spark.SparkContext - Created broadcast 14 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10891 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=4849217, maxMem=833492090
10891 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 315.1 KB, free 789.9 MB)
10942 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=5171910, maxMem=833492090
10942 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.0 KB, free 789.9 MB)
10943 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.5 MB)
10944 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_15_piece0
10945 [main] INFO org.apache.spark.SparkContext - Created broadcast 15 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
10955 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=5195505, maxMem=833492090
10955 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 315.1 KB, free 789.6 MB)
10997 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=5518198, maxMem=833492090
10998 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.0 KB, free 789.6 MB)
10999 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.5 MB)
10999 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_16_piece0
11000 [main] INFO org.apache.spark.SparkContext - Created broadcast 16 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11009 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=5541793, maxMem=833492090
11010 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 315.1 KB, free 789.3 MB)
11055 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23596) called with curMem=5864486, maxMem=833492090
11056 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.0 KB, free 789.3 MB)
11057 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.5 MB)
11057 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_17_piece0
11058 [main] INFO org.apache.spark.SparkContext - Created broadcast 17 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11082 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=5888082, maxMem=833492090
11083 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 315.1 KB, free 789.0 MB)
11125 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23594) called with curMem=6210775, maxMem=833492090
11126 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.0 KB, free 788.9 MB)
11127 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.5 MB)
11127 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_18_piece0
11129 [main] INFO org.apache.spark.SparkContext - Created broadcast 18 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11146 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=6234369, maxMem=833492090
11146 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 315.1 KB, free 788.6 MB)
11188 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=6557062, maxMem=833492090
11188 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 23.0 KB, free 788.6 MB)
11190 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.5 MB)
11194 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_19_piece0
11195 [main] INFO org.apache.spark.SparkContext - Created broadcast 19 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11217 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=6580657, maxMem=833492090
11218 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 315.1 KB, free 788.3 MB)
11295 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=6903350, maxMem=833492090
11296 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.0 KB, free 788.3 MB)
11298 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.4 MB)
11298 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_20_piece0
11299 [main] INFO org.apache.spark.SparkContext - Created broadcast 20 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11319 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=6926945, maxMem=833492090
11320 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 315.1 KB, free 788.0 MB)
11376 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23598) called with curMem=7249638, maxMem=833492090
11376 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.0 KB, free 787.9 MB)
11378 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.4 MB)
11381 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_21_piece0
11382 [main] INFO org.apache.spark.SparkContext - Created broadcast 21 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11396 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=7273236, maxMem=833492090
11399 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 315.1 KB, free 787.6 MB)
11447 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=7595929, maxMem=833492090
11447 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.0 KB, free 787.6 MB)
11448 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.4 MB)
11449 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_22_piece0
11450 [main] INFO org.apache.spark.SparkContext - Created broadcast 22 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11458 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=7619524, maxMem=833492090
11459 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 315.1 KB, free 787.3 MB)
11493 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23597) called with curMem=7942217, maxMem=833492090
11493 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.0 KB, free 787.3 MB)
11495 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_23_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.4 MB)
11496 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_23_piece0
11497 [main] INFO org.apache.spark.SparkContext - Created broadcast 23 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11518 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=7965814, maxMem=833492090
11518 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 315.1 KB, free 787.0 MB)
11551 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23600) called with curMem=8288507, maxMem=833492090
11552 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.0 KB, free 787.0 MB)
11553 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_24_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.3 MB)
11553 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_24_piece0
11555 [main] INFO org.apache.spark.SparkContext - Created broadcast 24 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11563 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=8312107, maxMem=833492090
11563 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 315.1 KB, free 786.6 MB)
11598 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23595) called with curMem=8634800, maxMem=833492090
11599 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.0 KB, free 786.6 MB)
11600 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_25_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.3 MB)
11600 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_25_piece0
11601 [main] INFO org.apache.spark.SparkContext - Created broadcast 25 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11609 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(322693) called with curMem=8658395, maxMem=833492090
11610 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 315.1 KB, free 786.3 MB)
11645 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(23600) called with curMem=8981088, maxMem=833492090
11646 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 23.0 KB, free 786.3 MB)
11647 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_26_piece0 in memory on localhost:60336 (size: 23.0 KB, free: 794.3 MB)
11648 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_26_piece0
11649 [main] INFO org.apache.spark.SparkContext - Created broadcast 26 from newAPIHadoopFile at ViewThroughCorrelation.scala:64
11690 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(11536) called with curMem=9004688, maxMem=833492090
11690 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 11.3 KB, free 786.3 MB)
11799 [main] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(156) called with curMem=9016224, maxMem=833492090
11812 [main] INFO org.apache.spark.storage.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 156.0 B, free 786.3 MB)
11814 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_27_piece0 in memory on localhost:60336 (size: 156.0 B, free: 794.3 MB)
11814 [main] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_27_piece0
11815 [main] INFO org.apache.spark.SparkContext - Created broadcast 27 from broadcast at ViewThroughCorrelation.scala:71
11974 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 58
12088 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 8
12096 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12110 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12117 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12124 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12131 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12139 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12146 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12153 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12159 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12166 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12172 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12181 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12187 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12195 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12200 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12205 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12210 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12216 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12222 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12228 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12235 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12241 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12250 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 6
12259 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 3
12422 [main] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
12513 [main] INFO org.apache.spark.SparkContext - Starting job: saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156
12570 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Registering RDD 81 (map at ViewThroughCorrelation.scala:81)
12577 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Registering RDD 82 (groupBy at RddHelper.scala:18)
12578 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Registering RDD 85 (map at ViewThroughCorrelation.scala:91)
12582 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156) with 83 output partitions (allowLocal=false)
12582 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Final stage: Stage 3(saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156)
12583 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 0, Stage 2)
12668 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents: List(Stage 0, Stage 2)
12825 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting Stage 0 (MapPartitionsRDD[81] at map at ViewThroughCorrelation.scala:81), which has no missing parents
12905 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(11216) called with curMem=9016380, maxMem=833492090
12906 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 11.0 KB, free 786.3 MB)
12953 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(3631) called with curMem=9027596, maxMem=833492090
12953 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.5 KB, free 786.3 MB)
12955 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_28_piece0 in memory on localhost:60336 (size: 3.5 KB, free: 794.3 MB)
12955 [dag-scheduler-event-loop] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_28_piece0
12956 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:839
13109 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 83 missing tasks from Stage 0 (MapPartitionsRDD[81] at map at ViewThroughCorrelation.scala:81)
13113 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 83 tasks
13168 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1945 bytes)
13173 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, ANY, 1945 bytes)
13179 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
13188 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Fetching hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar with timestamp 1434121754185
13192 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting Stage 1 (MapPartitionsRDD[82] at groupBy at RddHelper.scala:18), which has no missing parents
13193 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
13198 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(4376) called with curMem=9031227, maxMem=833492090
13199 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 4.3 KB, free 786.3 MB)
13245 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(2293) called with curMem=9035603, maxMem=833492090
13245 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.2 KB, free 786.3 MB)
13247 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_29_piece0 in memory on localhost:60336 (size: 2.2 KB, free: 794.3 MB)
13247 [dag-scheduler-event-loop] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_29_piece0
13248 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:839
13269 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 58 missing tasks from Stage 1 (MapPartitionsRDD[82] at groupBy at RddHelper.scala:18)
13270 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 58 tasks
13272 [Executor task launch worker-0] INFO org.apache.spark.util.Utils - Fetching hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar to /data/1/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/userFiles-df280fb2-0ab7-4e28-b926-d3b502b99768/fetchFileTemp6461776421018058204.tmp
13365 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Adding file:/data/1/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/userFiles-df280fb2-0ab7-4e28-b926-d3b502b99768/rtb-spark-viewthrough_2.10.jar to class loader
13414 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434038404012.avro:0+356989
13419 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
13420 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
13429 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434039578550.avro:0+30176
13430 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
13430 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
14527 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2013 bytes result sent to driver
14531 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, ANY, 1945 bytes)
14531 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
14561 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 1368 ms on localhost (1/83)
14561 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434039661252.avro:0+23900
14562 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
14562 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
15141 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2068 bytes result sent to driver
15144 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, ANY, 1945 bytes)
15144 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
15178 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2009 ms on localhost (2/83)
15205 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434039721318.avro:0+760283
15207 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
15207 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
15656 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2068 bytes result sent to driver
15659 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, ANY, 1945 bytes)
15669 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
15678 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 1140 ms on localhost (3/83)
15723 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434038403741.avro:0+903418
15726 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
15729 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
16623 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2068 bytes result sent to driver
16626 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5, localhost, ANY, 1945 bytes)
16626 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
16632 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 1484 ms on localhost (4/83)
16647 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434038405050.avro:0+567050
16648 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
16648 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
17062 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2068 bytes result sent to driver
17065 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 0.0 (TID 6, localhost, ANY, 1945 bytes)
17065 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 6.0 in stage 0.0 (TID 6)
17070 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 1408 ms on localhost (5/83)
17087 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434040791653.avro:0+40328
17088 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
17088 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
17339 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2068 bytes result sent to driver
17342 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 0.0 (TID 7, localhost, ANY, 1945 bytes)
17342 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 7.0 in stage 0.0 (TID 7)
17346 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 718 ms on localhost (6/83)
17369 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434040966414.avro:0+276517
17371 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
17371 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
17635 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 6.0 in stage 0.0 (TID 6). 2068 bytes result sent to driver
17637 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 0.0 (TID 8, localhost, ANY, 1945 bytes)
17637 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 8.0 in stage 0.0 (TID 8)
17643 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 0.0 (TID 6) in 574 ms on localhost (7/83)
17655 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15/2015-06-11-15--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434034800817.avro:0+1165040
17656 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
17656 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
17883 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 7.0 in stage 0.0 (TID 7). 2068 bytes result sent to driver
17886 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 0.0 (TID 9, localhost, ANY, 1945 bytes)
17886 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 9.0 in stage 0.0 (TID 9)
17890 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 0.0 (TID 7) in 546 ms on localhost (8/83)
17897 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15/2015-06-11-15--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434034802091.avro:0+898980
17898 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
17899 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
18227 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 8.0 in stage 0.0 (TID 8). 2068 bytes result sent to driver
18230 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 0.0 (TID 10, localhost, ANY, 1945 bytes)
18230 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 10.0 in stage 0.0 (TID 10)
18235 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 0.0 (TID 8) in 595 ms on localhost (9/83)
18236 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15/2015-06-11-15--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434034805116.avro:0+884285
18237 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
18237 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
18321 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 9.0 in stage 0.0 (TID 9). 2068 bytes result sent to driver
18323 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 0.0 (TID 11, localhost, ANY, 1930 bytes)
18324 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 11.0 in stage 0.0 (TID 11)
18329 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 0.0 (TID 9) in 439 ms on localhost (10/83)
18330 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14/2015-06-11-14--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434031203229.avro:0+1160691
18331 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
18331 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
18822 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 10.0 in stage 0.0 (TID 10). 2068 bytes result sent to driver
18824 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 0.0 (TID 12, localhost, ANY, 1930 bytes)
18824 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 12.0 in stage 0.0 (TID 12)
18829 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 0.0 (TID 10) in 596 ms on localhost (11/83)
18835 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14/2015-06-11-14--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434031200959.avro:0+897436
18836 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
18836 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
18932 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 11.0 in stage 0.0 (TID 11). 2068 bytes result sent to driver
18934 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 0.0 (TID 13, localhost, ANY, 1930 bytes)
18935 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 13.0 in stage 0.0 (TID 13)
18938 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 0.0 (TID 11) in 613 ms on localhost (12/83)
18944 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14/2015-06-11-14--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434031204241.avro:0+888800
18945 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
18945 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
19367 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 12.0 in stage 0.0 (TID 12). 2068 bytes result sent to driver
19370 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 0.0 (TID 14, localhost, ANY, 1915 bytes)
19370 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 14.0 in stage 0.0 (TID 14)
19375 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 0.0 (TID 12) in 548 ms on localhost (13/83)
19376 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13/2015-06-11-13--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434027604142.avro:0+1171341
19377 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
19377 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
19401 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 13.0 in stage 0.0 (TID 13). 2068 bytes result sent to driver
19403 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 0.0 (TID 15, localhost, ANY, 1915 bytes)
19403 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 15.0 in stage 0.0 (TID 15)
19408 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 0.0 (TID 13) in 470 ms on localhost (14/83)
19414 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13/2015-06-11-13--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434027605665.avro:0+883475
19415 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
19415 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
19842 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 14.0 in stage 0.0 (TID 14). 2068 bytes result sent to driver
19844 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 0.0 (TID 16, localhost, ANY, 1915 bytes)
19844 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 16.0 in stage 0.0 (TID 16)
19849 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 0.0 (TID 14) in 476 ms on localhost (15/83)
19853 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13/2015-06-11-13--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434027605022.avro:0+885488
19854 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
19854 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
19874 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 15.0 in stage 0.0 (TID 15). 2068 bytes result sent to driver
19876 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 0.0 (TID 17, localhost, ANY, 1900 bytes)
19876 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 17.0 in stage 0.0 (TID 17)
19883 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12/2015-06-11-12--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434024003794.avro:0+1164080
19883 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
19884 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
19885 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 0.0 (TID 15) in 475 ms on localhost (16/83)
20326 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 16.0 in stage 0.0 (TID 16). 2068 bytes result sent to driver
20328 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 0.0 (TID 18, localhost, ANY, 1900 bytes)
20328 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 18.0 in stage 0.0 (TID 18)
20332 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 0.0 (TID 16) in 485 ms on localhost (17/83)
20335 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12/2015-06-11-12--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434024003116.avro:0+890723
20335 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
20335 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
20446 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 17.0 in stage 0.0 (TID 17). 2068 bytes result sent to driver
20448 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 0.0 (TID 19, localhost, ANY, 1900 bytes)
20448 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 19.0 in stage 0.0 (TID 19)
20453 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 0.0 (TID 17) in 573 ms on localhost (18/83)
20456 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12/2015-06-11-12--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434024003795.avro:0+890505
20457 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
20457 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
20762 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 18.0 in stage 0.0 (TID 18). 2068 bytes result sent to driver
20765 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 0.0 (TID 20, localhost, ANY, 1885 bytes)
20765 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 20.0 in stage 0.0 (TID 20)
20770 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 0.0 (TID 18) in 439 ms on localhost (19/83)
20771 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11/2015-06-11-11--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434020401728.avro:0+1161930
20772 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
20772 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
20847 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 19.0 in stage 0.0 (TID 19). 2068 bytes result sent to driver
20849 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 0.0 (TID 21, localhost, ANY, 1885 bytes)
20850 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 21.0 in stage 0.0 (TID 21)
20853 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 0.0 (TID 19) in 403 ms on localhost (20/83)
20855 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11/2015-06-11-11--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434020405863.avro:0+895943
20856 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
20856 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21137 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 21.0 in stage 0.0 (TID 21). 2068 bytes result sent to driver
21139 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 0.0 (TID 22, localhost, ANY, 1885 bytes)
21140 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 22.0 in stage 0.0 (TID 22)
21142 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 0.0 (TID 21) in 292 ms on localhost (21/83)
21146 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11/2015-06-11-11--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434020402318.avro:0+888465
21147 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21147 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21188 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 20.0 in stage 0.0 (TID 20). 2068 bytes result sent to driver
21190 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 0.0 (TID 23, localhost, ANY, 1870 bytes)
21191 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 23.0 in stage 0.0 (TID 23)
21194 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 0.0 (TID 20) in 428 ms on localhost (22/83)
21202 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10/2015-06-11-10--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434016802736.avro:0+1150476
21203 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21203 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21534 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 22.0 in stage 0.0 (TID 22). 2068 bytes result sent to driver
21537 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 0.0 (TID 24, localhost, ANY, 1870 bytes)
21537 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 24.0 in stage 0.0 (TID 24)
21540 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 0.0 (TID 22) in 399 ms on localhost (23/83)
21549 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10/2015-06-11-10--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434016804771.avro:0+887059
21550 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21550 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21629 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 23.0 in stage 0.0 (TID 23). 2068 bytes result sent to driver
21632 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 0.0 (TID 25, localhost, ANY, 1870 bytes)
21632 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 25.0 in stage 0.0 (TID 25)
21637 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 0.0 (TID 23) in 443 ms on localhost (24/83)
21642 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10/2015-06-11-10--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434016800459.avro:0+904565
21643 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21643 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21913 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 25.0 in stage 0.0 (TID 25). 2068 bytes result sent to driver
21915 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 0.0 (TID 26, localhost, ANY, 1855 bytes)
21915 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 26.0 in stage 0.0 (TID 26)
21920 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 0.0 (TID 25) in 285 ms on localhost (25/83)
21923 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09/2015-06-11-09--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434013202685.avro:0+1153627
21924 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21924 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
21938 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 24.0 in stage 0.0 (TID 24). 2068 bytes result sent to driver
21940 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 0.0 (TID 27, localhost, ANY, 1855 bytes)
21940 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 27.0 in stage 0.0 (TID 27)
21945 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 0.0 (TID 24) in 405 ms on localhost (26/83)
21950 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09/2015-06-11-09--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434013205510.avro:0+889960
21952 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
21952 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
22252 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 26.0 in stage 0.0 (TID 26). 2068 bytes result sent to driver
22254 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 0.0 (TID 28, localhost, ANY, 1855 bytes)
22254 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 28.0 in stage 0.0 (TID 28)
22257 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 0.0 (TID 26) in 340 ms on localhost (27/83)
22269 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09/2015-06-11-09--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434013205544.avro:0+901650
22272 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
22272 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
22468 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 27.0 in stage 0.0 (TID 27). 2068 bytes result sent to driver
22470 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 0.0 (TID 29, localhost, ANY, 1840 bytes)
22470 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 29.0 in stage 0.0 (TID 29)
22475 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 0.0 (TID 27) in 532 ms on localhost (28/83)
22480 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08/2015-06-11-08--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434009600389.avro:0+1167650
22481 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
22481 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
22745 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 28.0 in stage 0.0 (TID 28). 2068 bytes result sent to driver
22747 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 0.0 (TID 30, localhost, ANY, 1840 bytes)
22747 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 30.0 in stage 0.0 (TID 30)
22751 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 0.0 (TID 28) in 495 ms on localhost (29/83)
22755 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08/2015-06-11-08--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434009603516.avro:0+898863
22756 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
22756 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
22840 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 29.0 in stage 0.0 (TID 29). 2068 bytes result sent to driver
22842 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 0.0 (TID 31, localhost, ANY, 1840 bytes)
22842 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 31.0 in stage 0.0 (TID 31)
22847 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 0.0 (TID 29) in 374 ms on localhost (30/83)
22848 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08/2015-06-11-08--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434009603706.avro:0+881194
22849 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
22849 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
23218 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 31.0 in stage 0.0 (TID 31). 2068 bytes result sent to driver
23220 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 0.0 (TID 32, localhost, ANY, 1825 bytes)
23220 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 32.0 in stage 0.0 (TID 32)
23224 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 30.0 in stage 0.0 (TID 30). 2068 bytes result sent to driver
23224 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 0.0 (TID 31) in 380 ms on localhost (31/83)
23225 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07/2015-06-11-07--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434006002398.avro:0+1171448
23225 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
23225 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
23226 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 0.0 (TID 33, localhost, ANY, 1825 bytes)
23227 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 33.0 in stage 0.0 (TID 33)
23231 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 0.0 (TID 30) in 480 ms on localhost (32/83)
23234 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07/2015-06-11-07--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434006004761.avro:0+876582
23235 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
23235 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
23622 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 32.0 in stage 0.0 (TID 32). 2068 bytes result sent to driver
23624 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 0.0 (TID 34, localhost, ANY, 1825 bytes)
23624 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 34.0 in stage 0.0 (TID 34)
23629 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07/2015-06-11-07--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434006006726.avro:0+900185
23629 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
23629 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
23632 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 0.0 (TID 32) in 407 ms on localhost (33/83)
23675 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 33.0 in stage 0.0 (TID 33). 2068 bytes result sent to driver
23677 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 0.0 (TID 35, localhost, ANY, 1810 bytes)
23677 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 35.0 in stage 0.0 (TID 35)
23682 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 0.0 (TID 33) in 452 ms on localhost (34/83)
23682 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06/2015-06-11-06--vtqaana-cloudera01.dealer.ddc-RTBImpression.1434002401323.avro:0+1159366
23683 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
23683 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
24034 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 35.0 in stage 0.0 (TID 35). 2068 bytes result sent to driver
24035 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 34.0 in stage 0.0 (TID 34). 2068 bytes result sent to driver
24035 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 0.0 (TID 36, localhost, ANY, 1810 bytes)
24035 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 36.0 in stage 0.0 (TID 36)
24040 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 0.0 (TID 35) in 359 ms on localhost (35/83)
24041 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 0.0 (TID 37, localhost, ANY, 1810 bytes)
24041 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 37.0 in stage 0.0 (TID 37)
24042 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06/2015-06-11-06--vtqaana-cloudera02.dealer.ddc-RTBImpression.1434002401433.avro:0+901062
24043 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
24043 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
24045 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 0.0 (TID 34) in 419 ms on localhost (36/83)
24046 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06/2015-06-11-06--vtqaana-cloudera03.dealer.ddc-RTBImpression.1434002400306.avro:0+886479
24047 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
24047 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
24394 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 37.0 in stage 0.0 (TID 37). 2068 bytes result sent to driver
24396 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 0.0 (TID 38, localhost, ANY, 1795 bytes)
24396 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 38.0 in stage 0.0 (TID 38)
24400 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 0.0 (TID 37) in 356 ms on localhost (37/83)
24405 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05/2015-06-11-05--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433998800565.avro:0+1159566
24407 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
24407 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
24460 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 36.0 in stage 0.0 (TID 36). 2068 bytes result sent to driver
24462 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 0.0 (TID 39, localhost, ANY, 1795 bytes)
24462 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 39.0 in stage 0.0 (TID 39)
24466 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 0.0 (TID 36) in 428 ms on localhost (38/83)
24468 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05/2015-06-11-05--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433998803661.avro:0+899133
24469 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
24469 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
24954 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 38.0 in stage 0.0 (TID 38). 2068 bytes result sent to driver
24956 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 0.0 (TID 40, localhost, ANY, 1795 bytes)
24956 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 40.0 in stage 0.0 (TID 40)
24960 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 0.0 (TID 38) in 562 ms on localhost (39/83)
24962 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05/2015-06-11-05--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433998802352.avro:0+892269
24964 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
24964 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
25036 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 39.0 in stage 0.0 (TID 39). 2068 bytes result sent to driver
25038 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 0.0 (TID 41, localhost, ANY, 1780 bytes)
25038 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 41.0 in stage 0.0 (TID 41)
25042 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 0.0 (TID 39) in 577 ms on localhost (40/83)
25044 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04/2015-06-11-04--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433995200102.avro:0+1158160
25045 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
25045 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
25453 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 41.0 in stage 0.0 (TID 41). 2068 bytes result sent to driver
25454 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 0.0 (TID 42, localhost, ANY, 1780 bytes)
25455 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 42.0 in stage 0.0 (TID 42)
25459 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 0.0 (TID 41) in 418 ms on localhost (41/83)
25461 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04/2015-06-11-04--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433995204332.avro:0+897206
25462 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
25462 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
25491 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 40.0 in stage 0.0 (TID 40). 2068 bytes result sent to driver
25493 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 0.0 (TID 43, localhost, ANY, 1780 bytes)
25497 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 0.0 (TID 40) in 539 ms on localhost (42/83)
25497 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 43.0 in stage 0.0 (TID 43)
25504 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04/2015-06-11-04--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433995200284.avro:0+889785
25506 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
25506 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
25921 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 43.0 in stage 0.0 (TID 43). 2068 bytes result sent to driver
25923 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 0.0 (TID 44, localhost, ANY, 1765 bytes)
25923 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 44.0 in stage 0.0 (TID 44)
25928 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 0.0 (TID 43) in 432 ms on localhost (43/83)
25930 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03/2015-06-11-03--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433991603695.avro:0+1164340
25933 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
25933 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
25943 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 42.0 in stage 0.0 (TID 42). 2068 bytes result sent to driver
25945 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 0.0 (TID 45, localhost, ANY, 1765 bytes)
25945 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 45.0 in stage 0.0 (TID 45)
25949 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 0.0 (TID 42) in 492 ms on localhost (44/83)
25952 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03/2015-06-11-03--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433991602326.avro:0+883613
25954 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
25954 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
26384 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 44.0 in stage 0.0 (TID 44). 2068 bytes result sent to driver
26385 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 0.0 (TID 46, localhost, ANY, 1765 bytes)
26385 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 45.0 in stage 0.0 (TID 45). 2068 bytes result sent to driver
26385 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 46.0 in stage 0.0 (TID 46)
26386 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 0.0 (TID 47, localhost, ANY, 1750 bytes)
26387 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 47.0 in stage 0.0 (TID 47)
26389 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 0.0 (TID 44) in 465 ms on localhost (45/83)
26390 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03/2015-06-11-03--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433991602110.avro:0+901993
26391 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
26391 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
26392 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02/2015-06-11-02--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433988004325.avro:0+1160071
26393 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
26393 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
26394 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 0.0 (TID 45) in 446 ms on localhost (46/83)
26784 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 46.0 in stage 0.0 (TID 46). 2068 bytes result sent to driver
26786 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 0.0 (TID 48, localhost, ANY, 1750 bytes)
26787 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 48.0 in stage 0.0 (TID 48)
26791 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 0.0 (TID 46) in 402 ms on localhost (47/83)
26794 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02/2015-06-11-02--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433988005763.avro:0+890624
26794 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 47.0 in stage 0.0 (TID 47). 2068 bytes result sent to driver
26795 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
26795 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
26796 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 0.0 (TID 49, localhost, ANY, 1750 bytes)
26796 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 49.0 in stage 0.0 (TID 49)
26801 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 0.0 (TID 47) in 411 ms on localhost (48/83)
26802 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02/2015-06-11-02--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433988005806.avro:0+889905
26803 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
26803 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
27129 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 49.0 in stage 0.0 (TID 49). 2068 bytes result sent to driver
27131 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 0.0 (TID 50, localhost, ANY, 1735 bytes)
27131 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 50.0 in stage 0.0 (TID 50)
27137 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 0.0 (TID 49) in 337 ms on localhost (49/83)
27138 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01/2015-06-11-01--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433984402746.avro:0+1146873
27139 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
27139 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
27176 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 48.0 in stage 0.0 (TID 48). 2068 bytes result sent to driver
27178 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 0.0 (TID 51, localhost, ANY, 1735 bytes)
27178 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 51.0 in stage 0.0 (TID 51)
27181 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 0.0 (TID 48) in 393 ms on localhost (50/83)
27185 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01/2015-06-11-01--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433984403928.avro:0+894241
27186 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
27186 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
27519 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 51.0 in stage 0.0 (TID 51). 2068 bytes result sent to driver
27521 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 0.0 (TID 52, localhost, ANY, 1735 bytes)
27522 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 52.0 in stage 0.0 (TID 52)
27525 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 0.0 (TID 51) in 344 ms on localhost (51/83)
27529 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01/2015-06-11-01--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433984400889.avro:0+906770
27531 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
27531 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
27664 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 50.0 in stage 0.0 (TID 50). 2068 bytes result sent to driver
27665 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 0.0 (TID 53, localhost, ANY, 1720 bytes)
27666 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 53.0 in stage 0.0 (TID 53)
27670 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 0.0 (TID 50) in 536 ms on localhost (52/83)
27673 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00/2015-06-11-00--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433980806140.avro:0+1171929
27674 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
27674 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
28018 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 52.0 in stage 0.0 (TID 52). 2068 bytes result sent to driver
28019 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 0.0 (TID 54, localhost, ANY, 1720 bytes)
28022 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 54.0 in stage 0.0 (TID 54)
28024 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 0.0 (TID 52) in 501 ms on localhost (53/83)
28029 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00/2015-06-11-00--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433980800850.avro:0+893971
28030 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
28030 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
28116 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 53.0 in stage 0.0 (TID 53). 2068 bytes result sent to driver
28118 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 0.0 (TID 55, localhost, ANY, 1720 bytes)
28131 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 0.0 (TID 53) in 455 ms on localhost (54/83)
28135 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 55.0 in stage 0.0 (TID 55)
28142 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00/2015-06-11-00--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433980801681.avro:0+877571
28143 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
28143 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
28547 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 54.0 in stage 0.0 (TID 54). 2068 bytes result sent to driver
28549 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 0.0 (TID 56, localhost, ANY, 1705 bytes)
28550 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 56.0 in stage 0.0 (TID 56)
28555 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 0.0 (TID 54) in 532 ms on localhost (55/83)
28557 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23/2015-06-10-23--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433977205595.avro:0+1156900
28558 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
28558 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
28695 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 55.0 in stage 0.0 (TID 55). 2068 bytes result sent to driver
28697 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 0.0 (TID 57, localhost, ANY, 1705 bytes)
28698 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 57.0 in stage 0.0 (TID 57)
28702 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 0.0 (TID 55) in 580 ms on localhost (56/83)
28704 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23/2015-06-10-23--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433977201830.avro:0+904972
28705 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
28705 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
29168 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 56.0 in stage 0.0 (TID 56). 2068 bytes result sent to driver
29170 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 0.0 (TID 58, localhost, ANY, 1705 bytes)
29173 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 0.0 (TID 56) in 622 ms on localhost (57/83)
29175 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 58.0 in stage 0.0 (TID 58)
29182 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23/2015-06-10-23--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433977205993.avro:0+881463
29183 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
29183 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
29277 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 57.0 in stage 0.0 (TID 57). 2068 bytes result sent to driver
29278 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 0.0 (TID 59, localhost, ANY, 1690 bytes)
29284 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 0.0 (TID 57) in 583 ms on localhost (58/83)
29284 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 59.0 in stage 0.0 (TID 59)
29291 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22/2015-06-10-22--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433973600312.avro:0+1171951
29292 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
29292 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
29698 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 58.0 in stage 0.0 (TID 58). 2068 bytes result sent to driver
29700 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 0.0 (TID 60, localhost, ANY, 1690 bytes)
29706 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 0.0 (TID 58) in 532 ms on localhost (59/83)
29706 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 60.0 in stage 0.0 (TID 60)
29711 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22/2015-06-10-22--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433973604651.avro:0+899451
29713 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
29713 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
29779 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 59.0 in stage 0.0 (TID 59). 2068 bytes result sent to driver
29781 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 0.0 (TID 61, localhost, ANY, 1690 bytes)
29782 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 61.0 in stage 0.0 (TID 61)
29785 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 0.0 (TID 59) in 504 ms on localhost (60/83)
29788 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22/2015-06-10-22--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433973601340.avro:0+882390
29788 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
29788 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30111 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 60.0 in stage 0.0 (TID 60). 2068 bytes result sent to driver
30112 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 0.0 (TID 62, localhost, ANY, 1675 bytes)
30113 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 62.0 in stage 0.0 (TID 62)
30113 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 61.0 in stage 0.0 (TID 61). 2068 bytes result sent to driver
30114 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 0.0 (TID 63, localhost, ANY, 1675 bytes)
30114 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 63.0 in stage 0.0 (TID 63)
30116 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21/2015-06-10-21--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433970003857.avro:0+1173294
30117 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30117 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30119 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 0.0 (TID 60) in 415 ms on localhost (61/83)
30120 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21/2015-06-10-21--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433970000058.avro:0+888017
30121 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30121 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30123 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 0.0 (TID 61) in 339 ms on localhost (62/83)
30499 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 62.0 in stage 0.0 (TID 62). 2068 bytes result sent to driver
30500 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 0.0 (TID 64, localhost, ANY, 1675 bytes)
30501 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 64.0 in stage 0.0 (TID 64)
30504 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 63.0 in stage 0.0 (TID 63). 2068 bytes result sent to driver
30505 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 0.0 (TID 62) in 390 ms on localhost (63/83)
30506 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 0.0 (TID 65, localhost, ANY, 1660 bytes)
30506 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 65.0 in stage 0.0 (TID 65)
30507 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21/2015-06-10-21--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433970005023.avro:0+890311
30508 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30508 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30512 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 0.0 (TID 63) in 393 ms on localhost (64/83)
30523 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20/2015-06-10-20--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433966405514.avro:0+1155616
30524 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30524 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30961 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 65.0 in stage 0.0 (TID 65). 2068 bytes result sent to driver
30963 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 0.0 (TID 66, localhost, ANY, 1660 bytes)
30963 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 66.0 in stage 0.0 (TID 66)
30968 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 0.0 (TID 65) in 458 ms on localhost (65/83)
30970 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20/2015-06-10-20--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433966403682.avro:0+898308
30971 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30971 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
30979 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 64.0 in stage 0.0 (TID 64). 2068 bytes result sent to driver
30981 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 0.0 (TID 67, localhost, ANY, 1660 bytes)
30981 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 67.0 in stage 0.0 (TID 67)
30983 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 0.0 (TID 64) in 482 ms on localhost (66/83)
30988 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20/2015-06-10-20--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433966400528.avro:0+890063
30989 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
30989 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
31454 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 67.0 in stage 0.0 (TID 67). 2068 bytes result sent to driver
31456 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 0.0 (TID 68, localhost, ANY, 1645 bytes)
31456 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 68.0 in stage 0.0 (TID 68)
31461 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 0.0 (TID 67) in 477 ms on localhost (67/83)
31462 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19/2015-06-10-19--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433962805343.avro:0+1167130
31463 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
31463 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
31496 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 66.0 in stage 0.0 (TID 66). 2068 bytes result sent to driver
31497 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 0.0 (TID 69, localhost, ANY, 1645 bytes)
31498 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 69.0 in stage 0.0 (TID 69)
31503 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19/2015-06-10-19--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433962801058.avro:0+902886
31503 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 0.0 (TID 66) in 536 ms on localhost (68/83)
31504 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
31504 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
31963 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 68.0 in stage 0.0 (TID 68). 2068 bytes result sent to driver
31965 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 0.0 (TID 70, localhost, ANY, 1645 bytes)
31965 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 70.0 in stage 0.0 (TID 70)
31969 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 0.0 (TID 68) in 510 ms on localhost (69/83)
31972 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19/2015-06-10-19--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433962802978.avro:0+876264
31973 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
31973 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
32045 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 69.0 in stage 0.0 (TID 69). 2068 bytes result sent to driver
32047 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 0.0 (TID 71, localhost, ANY, 1630 bytes)
32048 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 71.0 in stage 0.0 (TID 71)
32051 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 0.0 (TID 69) in 551 ms on localhost (70/83)
32054 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18/2015-06-10-18--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433959204642.avro:0+1165340
32055 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
32056 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
32532 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 70.0 in stage 0.0 (TID 70). 2068 bytes result sent to driver
32534 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 0.0 (TID 72, localhost, ANY, 1630 bytes)
32538 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 0.0 (TID 70) in 571 ms on localhost (71/83)
32538 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 72.0 in stage 0.0 (TID 72)
32544 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18/2015-06-10-18--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433959201451.avro:0+901256
32545 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
32545 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
32582 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 71.0 in stage 0.0 (TID 71). 2068 bytes result sent to driver
32583 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 0.0 (TID 73, localhost, ANY, 1630 bytes)
32585 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 73.0 in stage 0.0 (TID 73)
32587 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 0.0 (TID 71) in 537 ms on localhost (72/83)
32593 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18/2015-06-10-18--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433959203519.avro:0+879799
32594 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
32594 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
33096 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 73.0 in stage 0.0 (TID 73). 2068 bytes result sent to driver
33098 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 0.0 (TID 74, localhost, ANY, 1615 bytes)
33098 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 74.0 in stage 0.0 (TID 74)
33103 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 0.0 (TID 73) in 516 ms on localhost (73/83)
33104 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433955604034.avro:0+267822
33105 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
33105 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
33161 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 72.0 in stage 0.0 (TID 72). 2068 bytes result sent to driver
33162 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 0.0 (TID 75, localhost, ANY, 1615 bytes)
33164 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 75.0 in stage 0.0 (TID 75)
33166 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 0.0 (TID 72) in 630 ms on localhost (74/83)
33174 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433956431489.avro:0+892379
33175 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
33175 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
33592 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 74.0 in stage 0.0 (TID 74). 2068 bytes result sent to driver
33593 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 0.0 (TID 76, localhost, ANY, 1615 bytes)
33599 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 0.0 (TID 74) in 497 ms on localhost (75/83)
33599 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 76.0 in stage 0.0 (TID 76)
33605 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433955602944.avro:0+200896
33606 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
33606 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
33621 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 75.0 in stage 0.0 (TID 75). 2068 bytes result sent to driver
33622 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 0.0 (TID 77, localhost, ANY, 1615 bytes)
33628 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 0.0 (TID 75) in 462 ms on localhost (76/83)
33629 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 77.0 in stage 0.0 (TID 77)
33634 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433956458140.avro:0+702170
33635 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
33635 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
34048 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 76.0 in stage 0.0 (TID 76). 2068 bytes result sent to driver
34049 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 0.0 (TID 78, localhost, ANY, 1615 bytes)
34050 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 78.0 in stage 0.0 (TID 78)
34054 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 0.0 (TID 76) in 457 ms on localhost (77/83)
34055 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433955605476.avro:0+219067
34056 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
34056 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
34107 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 77.0 in stage 0.0 (TID 77). 2068 bytes result sent to driver
34108 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 0.0 (TID 79, localhost, ANY, 1615 bytes)
34108 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 79.0 in stage 0.0 (TID 79)
34113 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 0.0 (TID 77) in 487 ms on localhost (78/83)
34114 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17/2015-06-10-17--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433956499252.avro:0+667118
34115 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
34115 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
34453 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 78.0 in stage 0.0 (TID 78). 2068 bytes result sent to driver
34455 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 0.0 (TID 80, localhost, ANY, 1600 bytes)
34459 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 0.0 (TID 78) in 407 ms on localhost (79/83)
34459 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 80.0 in stage 0.0 (TID 80)
34465 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16/2015-06-10-16--vtqaana-cloudera01.dealer.ddc-RTBImpression.1433952000409.avro:0+1130815
34467 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
34467 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
34617 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 79.0 in stage 0.0 (TID 79). 2068 bytes result sent to driver
34619 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 0.0 (TID 81, localhost, ANY, 1600 bytes)
34619 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 81.0 in stage 0.0 (TID 81)
34622 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 0.0 (TID 79) in 512 ms on localhost (80/83)
34624 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16/2015-06-10-16--vtqaana-cloudera02.dealer.ddc-RTBImpression.1433952002094.avro:0+902169
34625 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
34625 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
34931 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 80.0 in stage 0.0 (TID 80). 2068 bytes result sent to driver
34932 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 0.0 (TID 82, localhost, ANY, 1600 bytes)
34933 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 82.0 in stage 0.0 (TID 82)
34937 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 0.0 (TID 80) in 479 ms on localhost (81/83)
34938 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16/2015-06-10-16--vtqaana-cloudera03.dealer.ddc-RTBImpression.1433952000544.avro:0+915053
34939 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
34939 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35088 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 81.0 in stage 0.0 (TID 81). 2068 bytes result sent to driver
35091 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 83, localhost, ANY, 1489 bytes)
35093 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 83)
35095 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 0.0 (TID 81) in 473 ms on localhost (82/83)
35098 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434038426804.avro:0+1788
35099 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
35099 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35568 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 82.0 in stage 0.0 (TID 82). 2068 bytes result sent to driver
35569 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 84, localhost, ANY, 1489 bytes)
35570 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 84)
35578 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Stage 0 (map at ViewThroughCorrelation.scala:81) finished in 22.446 s
35579 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
35579 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - running: Set(Stage 1)
35580 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - waiting: Set(Stage 2, Stage 3)
35580 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - failed: Set()
35583 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 0.0 (TID 82) in 638 ms on localhost (83/83)
35586 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool
35588 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434038671986.avro:0+1788
35589 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
35589 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35596 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 1)
35611 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents for Stage 3: List(Stage 2)
35632 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 83). 2043 bytes result sent to driver
35633 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 85, localhost, ANY, 1489 bytes)
35633 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 85)
35637 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434038757309.avro:0+1788
35638 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
35638 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35639 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 83) in 543 ms on localhost (1/58)
35859 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 85). 2043 bytes result sent to driver
35861 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 86, localhost, ANY, 1489 bytes)
35861 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 86)
35863 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 85) in 229 ms on localhost (2/58)
35864 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434038907641.avro:0+1788
35865 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
35865 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35877 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 84). 2043 bytes result sent to driver
35879 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 87, localhost, ANY, 1489 bytes)
35879 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 87)
35882 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039018022.avro:0+1788
35882 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
35882 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
35883 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 84) in 310 ms on localhost (3/58)
36099 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 86). 2043 bytes result sent to driver
36100 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 88, localhost, ANY, 1489 bytes)
36101 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 88)
36104 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039273230.avro:0+1788
36105 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36105 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36106 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 87). 2043 bytes result sent to driver
36107 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 86) in 241 ms on localhost (4/58)
36108 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 1.0 (TID 89, localhost, ANY, 1489 bytes)
36108 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 6.0 in stage 1.0 (TID 89)
36111 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039378677.avro:0+1788
36112 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36112 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36113 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 87) in 230 ms on localhost (5/58)
36326 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 6.0 in stage 1.0 (TID 89). 2043 bytes result sent to driver
36328 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 1.0 (TID 90, localhost, ANY, 1489 bytes)
36328 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 7.0 in stage 1.0 (TID 90)
36332 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039598882.avro:0+1788
36332 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 1.0 (TID 89) in 221 ms on localhost (6/58)
36333 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36333 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36466 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 88). 2043 bytes result sent to driver
36467 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 1.0 (TID 91, localhost, ANY, 1489 bytes)
36468 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 8.0 in stage 1.0 (TID 91)
36471 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039710037.avro:0+1788
36472 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 88) in 368 ms on localhost (7/58)
36472 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36472 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36571 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 7.0 in stage 1.0 (TID 90). 2043 bytes result sent to driver
36573 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 1.0 (TID 92, localhost, ANY, 1489 bytes)
36573 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 9.0 in stage 1.0 (TID 92)
36577 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039806344.avro:0+1788
36577 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 1.0 (TID 90) in 246 ms on localhost (8/58)
36578 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36578 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36753 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 8.0 in stage 1.0 (TID 91). 2043 bytes result sent to driver
36754 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 1.0 (TID 93, localhost, ANY, 1489 bytes)
36754 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 10.0 in stage 1.0 (TID 93)
36758 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434039926516.avro:0+1788
36759 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 1.0 (TID 91) in 287 ms on localhost (9/58)
36759 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36759 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36806 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 9.0 in stage 1.0 (TID 92). 2043 bytes result sent to driver
36807 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 1.0 (TID 94, localhost, ANY, 1489 bytes)
36807 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 11.0 in stage 1.0 (TID 94)
36809 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434040151714.avro:0+1788
36810 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36810 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36811 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 1.0 (TID 92) in 235 ms on localhost (10/58)
36991 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 10.0 in stage 1.0 (TID 93). 2043 bytes result sent to driver
36993 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 1.0 (TID 95, localhost, ANY, 1489 bytes)
36993 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 12.0 in stage 1.0 (TID 95)
36995 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434040276986.avro:0+1788
36996 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
36996 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
36997 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 1.0 (TID 93) in 240 ms on localhost (11/58)
37093 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 11.0 in stage 1.0 (TID 94). 2043 bytes result sent to driver
37106 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 1.0 (TID 96, localhost, ANY, 1489 bytes)
37107 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 13.0 in stage 1.0 (TID 96)
37111 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434040727151.avro:0+1788
37112 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37112 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37115 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 1.0 (TID 94) in 305 ms on localhost (12/58)
37244 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 12.0 in stage 1.0 (TID 95). 2043 bytes result sent to driver
37245 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 1.0 (TID 97, localhost, ANY, 1489 bytes)
37249 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 1.0 (TID 95) in 254 ms on localhost (13/58)
37251 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 14.0 in stage 1.0 (TID 97)
37254 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434040857300.avro:0+1788
37255 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37255 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37355 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 13.0 in stage 1.0 (TID 96). 2043 bytes result sent to driver
37356 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 1.0 (TID 98, localhost, ANY, 1489 bytes)
37357 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 15.0 in stage 1.0 (TID 98)
37360 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434040897467.avro:0+1788
37360 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 1.0 (TID 96) in 251 ms on localhost (14/58)
37362 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37362 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37499 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 14.0 in stage 1.0 (TID 97). 2043 bytes result sent to driver
37501 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 1.0 (TID 99, localhost, ANY, 1489 bytes)
37501 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 16.0 in stage 1.0 (TID 99)
37505 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 1.0 (TID 97) in 256 ms on localhost (15/58)
37508 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041112629.avro:0+1788
37509 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37509 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37613 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 15.0 in stage 1.0 (TID 98). 2043 bytes result sent to driver
37615 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 1.0 (TID 100, localhost, ANY, 1489 bytes)
37616 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 17.0 in stage 1.0 (TID 100)
37622 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 1.0 (TID 98) in 260 ms on localhost (16/58)
37622 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041328049.avro:0+1788
37623 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37623 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37803 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 16.0 in stage 1.0 (TID 99). 2043 bytes result sent to driver
37805 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 1.0 (TID 101, localhost, ANY, 1489 bytes)
37806 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 18.0 in stage 1.0 (TID 101)
37808 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 1.0 (TID 99) in 306 ms on localhost (17/58)
37809 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041358194.avro:0+1788
37809 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37809 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
37874 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 17.0 in stage 1.0 (TID 100). 2043 bytes result sent to driver
37875 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 1.0 (TID 102, localhost, ANY, 1489 bytes)
37875 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 19.0 in stage 1.0 (TID 102)
37879 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041413458.avro:0+1788
37880 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 1.0 (TID 100) in 261 ms on localhost (18/58)
37880 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
37880 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38034 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 18.0 in stage 1.0 (TID 101). 2043 bytes result sent to driver
38036 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 1.0 (TID 103, localhost, ANY, 1489 bytes)
38036 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 20.0 in stage 1.0 (TID 103)
38040 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 1.0 (TID 101) in 231 ms on localhost (19/58)
38044 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041638595.avro:0+1788
38044 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38045 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38108 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 19.0 in stage 1.0 (TID 102). 2043 bytes result sent to driver
38109 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 1.0 (TID 104, localhost, ANY, 1489 bytes)
38110 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 21.0 in stage 1.0 (TID 104)
38113 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 1.0 (TID 102) in 235 ms on localhost (20/58)
38114 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041798743.avro:0+1788
38115 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38115 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38354 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 20.0 in stage 1.0 (TID 103). 2043 bytes result sent to driver
38355 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 1.0 (TID 105, localhost, ANY, 1489 bytes)
38356 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 22.0 in stage 1.0 (TID 105)
38358 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041873948.avro:0+1788
38359 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38359 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38359 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 1.0 (TID 103) in 320 ms on localhost (21/58)
38435 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 21.0 in stage 1.0 (TID 104). 2043 bytes result sent to driver
38436 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 1.0 (TID 106, localhost, ANY, 1489 bytes)
38441 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 1.0 (TID 104) in 329 ms on localhost (22/58)
38441 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 23.0 in stage 1.0 (TID 106)
38446 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera01.dealer.ddc-RTBPixallHit.1434041909089.avro:0+1788
38447 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38447 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38686 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 22.0 in stage 1.0 (TID 105). 2043 bytes result sent to driver
38687 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 1.0 (TID 107, localhost, ANY, 1489 bytes)
38687 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 24.0 in stage 1.0 (TID 107)
38691 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434038435544.avro:0+1788
38691 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 1.0 (TID 105) in 333 ms on localhost (23/58)
38692 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38692 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
38743 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 23.0 in stage 1.0 (TID 106). 2043 bytes result sent to driver
38744 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 1.0 (TID 108, localhost, ANY, 1489 bytes)
38744 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 25.0 in stage 1.0 (TID 108)
38748 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 1.0 (TID 106) in 308 ms on localhost (24/58)
38748 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434038530808.avro:0+1788
38749 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
38749 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39091 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 24.0 in stage 1.0 (TID 107). 2043 bytes result sent to driver
39092 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 1.0 (TID 109, localhost, ANY, 1489 bytes)
39093 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 26.0 in stage 1.0 (TID 109)
39096 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434038810965.avro:0+1788
39097 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 1.0 (TID 107) in 406 ms on localhost (25/58)
39097 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39097 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39097 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 25.0 in stage 1.0 (TID 108). 2043 bytes result sent to driver
39098 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 1.0 (TID 110, localhost, ANY, 1489 bytes)
39099 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 27.0 in stage 1.0 (TID 110)
39102 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434039191192.avro:0+1788
39103 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 1.0 (TID 108) in 356 ms on localhost (26/58)
39106 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39106 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39432 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 27.0 in stage 1.0 (TID 110). 2043 bytes result sent to driver
39433 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 1.0 (TID 111, localhost, ANY, 1489 bytes)
39438 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 28.0 in stage 1.0 (TID 111)
39438 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 1.0 (TID 110) in 335 ms on localhost (27/58)
39442 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434039221434.avro:0+1788
39443 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39443 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39509 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 26.0 in stage 1.0 (TID 109). 2043 bytes result sent to driver
39510 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 1.0 (TID 112, localhost, ANY, 1489 bytes)
39511 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 29.0 in stage 1.0 (TID 112)
39514 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434039466596.avro:0+1788
39515 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39515 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 1.0 (TID 109) in 420 ms on localhost (28/58)
39515 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39735 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 28.0 in stage 1.0 (TID 111). 2043 bytes result sent to driver
39736 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 1.0 (TID 113, localhost, ANY, 1489 bytes)
39737 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 30.0 in stage 1.0 (TID 113)
39739 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 1.0 (TID 111) in 304 ms on localhost (29/58)
39741 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434039766868.avro:0+1788
39742 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39742 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
39843 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 29.0 in stage 1.0 (TID 112). 2043 bytes result sent to driver
39844 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 1.0 (TID 114, localhost, ANY, 1489 bytes)
39849 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 1.0 (TID 112) in 335 ms on localhost (30/58)
39849 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 31.0 in stage 1.0 (TID 114)
39853 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434039792039.avro:0+1788
39854 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
39854 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40094 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 30.0 in stage 1.0 (TID 113). 2043 bytes result sent to driver
40095 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 1.0 (TID 115, localhost, ANY, 1489 bytes)
40099 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 32.0 in stage 1.0 (TID 115)
40099 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 1.0 (TID 113) in 360 ms on localhost (31/58)
40102 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434040017224.avro:0+1788
40103 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40103 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40185 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 31.0 in stage 1.0 (TID 114). 2043 bytes result sent to driver
40186 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 1.0 (TID 116, localhost, ANY, 1489 bytes)
40191 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 1.0 (TID 114) in 342 ms on localhost (32/58)
40191 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 33.0 in stage 1.0 (TID 116)
40194 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434040342390.avro:0+1788
40195 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40195 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40568 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 32.0 in stage 1.0 (TID 115). 2043 bytes result sent to driver
40569 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 1.0 (TID 117, localhost, ANY, 1489 bytes)
40570 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 34.0 in stage 1.0 (TID 117)
40573 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434040437519.avro:0+2331
40573 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 33.0 in stage 1.0 (TID 116). 2043 bytes result sent to driver
40574 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 1.0 (TID 115) in 476 ms on localhost (33/58)
40575 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 1.0 (TID 118, localhost, ANY, 1489 bytes)
40575 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 35.0 in stage 1.0 (TID 118)
40577 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40577 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40578 [Executor task launch worker-1] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434040857719.avro:0+1788
40579 [Executor task launch worker-1] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40579 [Executor task launch worker-1] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40580 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 1.0 (TID 116) in 391 ms on localhost (34/58)
40851 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 35.0 in stage 1.0 (TID 118). 2043 bytes result sent to driver
40852 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 1.0 (TID 119, localhost, ANY, 1489 bytes)
40854 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 36.0 in stage 1.0 (TID 119)
40857 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 1.0 (TID 118) in 278 ms on localhost (35/58)
40857 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434041142867.avro:0+1788
40858 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40858 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
40870 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 34.0 in stage 1.0 (TID 117). 2043 bytes result sent to driver
40872 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 1.0 (TID 120, localhost, ANY, 1489 bytes)
40876 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 1.0 (TID 117) in 303 ms on localhost (36/58)
40877 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 37.0 in stage 1.0 (TID 120)
40880 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434041173006.avro:0+1788
40881 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
40881 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41253 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 37.0 in stage 1.0 (TID 120). 2043 bytes result sent to driver
41254 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 1.0 (TID 121, localhost, ANY, 1489 bytes)
41255 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 38.0 in stage 1.0 (TID 121)
41258 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434041398145.avro:0+1788
41258 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41258 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41259 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 1.0 (TID 120) in 383 ms on localhost (37/58)
41312 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 36.0 in stage 1.0 (TID 119). 2043 bytes result sent to driver
41313 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 1.0 (TID 122, localhost, ANY, 1489 bytes)
41314 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 39.0 in stage 1.0 (TID 122)
41316 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434041653288.avro:0+2487
41317 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41317 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41318 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 1.0 (TID 119) in 461 ms on localhost (38/58)
41476 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 38.0 in stage 1.0 (TID 121). 2043 bytes result sent to driver
41477 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 1.0 (TID 123, localhost, ANY, 1489 bytes)
41478 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 40.0 in stage 1.0 (TID 123)
41481 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 1.0 (TID 121) in 224 ms on localhost (39/58)
41481 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera02.dealer.ddc-RTBPixallHit.1434041906462.avro:0+1788
41482 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41482 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41603 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 39.0 in stage 1.0 (TID 122). 2043 bytes result sent to driver
41604 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 1.0 (TID 124, localhost, ANY, 1489 bytes)
41605 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 41.0 in stage 1.0 (TID 124)
41608 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434038536583.avro:0+1788
41609 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 1.0 (TID 122) in 292 ms on localhost (40/58)
41609 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41610 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41773 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 40.0 in stage 1.0 (TID 123). 2043 bytes result sent to driver
41775 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 1.0 (TID 125, localhost, ANY, 1489 bytes)
41775 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 42.0 in stage 1.0 (TID 125)
41778 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434038741759.avro:0+1788
41779 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 1.0 (TID 123) in 299 ms on localhost (41/58)
41779 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41779 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
41951 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 41.0 in stage 1.0 (TID 124). 2043 bytes result sent to driver
41953 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 1.0 (TID 126, localhost, ANY, 1489 bytes)
41953 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 43.0 in stage 1.0 (TID 126)
41957 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 1.0 (TID 124) in 349 ms on localhost (42/58)
41966 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434038966958.avro:0+1788
41967 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
41967 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42118 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 42.0 in stage 1.0 (TID 125). 2043 bytes result sent to driver
42120 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 1.0 (TID 127, localhost, ANY, 1489 bytes)
42120 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 44.0 in stage 1.0 (TID 127)
42123 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434039267140.avro:0+1788
42123 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 1.0 (TID 125) in 346 ms on localhost (43/58)
42124 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42124 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42254 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 43.0 in stage 1.0 (TID 126). 2043 bytes result sent to driver
42256 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 1.0 (TID 128, localhost, ANY, 1489 bytes)
42256 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 45.0 in stage 1.0 (TID 128)
42259 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434039287415.avro:0+2346
42260 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42260 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42261 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 1.0 (TID 126) in 304 ms on localhost (44/58)
42343 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 44.0 in stage 1.0 (TID 127). 2043 bytes result sent to driver
42345 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 1.0 (TID 129, localhost, ANY, 1489 bytes)
42345 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 46.0 in stage 1.0 (TID 129)
42348 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434039802726.avro:0+1788
42349 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 1.0 (TID 127) in 226 ms on localhost (45/58)
42349 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42349 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42552 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 45.0 in stage 1.0 (TID 128). 2043 bytes result sent to driver
42553 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 1.0 (TID 130, localhost, ANY, 1489 bytes)
42553 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 47.0 in stage 1.0 (TID 130)
42556 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434039873299.avro:0+1786
42556 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42556 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42558 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 1.0 (TID 128) in 299 ms on localhost (46/58)
42630 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 46.0 in stage 1.0 (TID 129). 2043 bytes result sent to driver
42631 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 1.0 (TID 131, localhost, ANY, 1489 bytes)
42631 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 48.0 in stage 1.0 (TID 131)
42634 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434040158442.avro:0+1788
42635 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 1.0 (TID 129) in 287 ms on localhost (47/58)
42635 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42635 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42761 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 47.0 in stage 1.0 (TID 130). 2043 bytes result sent to driver
42762 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 1.0 (TID 132, localhost, ANY, 1489 bytes)
42762 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 49.0 in stage 1.0 (TID 132)
42765 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434040698707.avro:0+1788
42765 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42765 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42765 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 1.0 (TID 130) in 209 ms on localhost (48/58)
42929 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 48.0 in stage 1.0 (TID 131). 2043 bytes result sent to driver
42930 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 1.0 (TID 133, localhost, ANY, 1489 bytes)
42931 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 50.0 in stage 1.0 (TID 133)
42934 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434040793620.avro:0+1788
42935 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 1.0 (TID 131) in 301 ms on localhost (49/58)
42935 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
42935 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
42989 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 49.0 in stage 1.0 (TID 132). 2043 bytes result sent to driver
42991 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 1.0 (TID 134, localhost, ANY, 1489 bytes)
42991 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 51.0 in stage 1.0 (TID 134)
43001 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041024587.avro:0+1788
43002 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 1.0 (TID 132) in 229 ms on localhost (50/58)
43002 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43002 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
43153 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 50.0 in stage 1.0 (TID 133). 2043 bytes result sent to driver
43154 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 1.0 (TID 135, localhost, ANY, 1489 bytes)
43155 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 52.0 in stage 1.0 (TID 135)
43158 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041219761.avro:0+1788
43159 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 1.0 (TID 133) in 224 ms on localhost (51/58)
43159 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43159 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
43285 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 51.0 in stage 1.0 (TID 134). 2043 bytes result sent to driver
43286 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 1.0 (TID 136, localhost, ANY, 1489 bytes)
43286 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 53.0 in stage 1.0 (TID 136)
43290 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041354941.avro:0+1788
43290 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 1.0 (TID 134) in 296 ms on localhost (52/58)
43291 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43291 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
43518 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 52.0 in stage 1.0 (TID 135). 2043 bytes result sent to driver
43520 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 1.0 (TID 137, localhost, ANY, 1489 bytes)
43520 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 54.0 in stage 1.0 (TID 137)
43522 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041455120.avro:0+1788
43523 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43523 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
43524 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 1.0 (TID 135) in 367 ms on localhost (53/58)
43555 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 53.0 in stage 1.0 (TID 136). 2043 bytes result sent to driver
43556 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 1.0 (TID 138, localhost, ANY, 1489 bytes)
43556 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 55.0 in stage 1.0 (TID 138)
43558 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041755357.avro:0+1788
43559 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43559 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
43560 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 1.0 (TID 136) in 271 ms on localhost (54/58)
43731 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 55.0 in stage 1.0 (TID 138). 2043 bytes result sent to driver
43732 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 1.0 (TID 139, localhost, ANY, 1489 bytes)
43732 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 56.0 in stage 1.0 (TID 139)
43735 [Executor task launch worker-2] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041795493.avro:0+1788
43735 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 1.0 (TID 138) in 177 ms on localhost (55/58)
43736 [Executor task launch worker-2] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
43736 [Executor task launch worker-2] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
44025 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 54.0 in stage 1.0 (TID 137). 2043 bytes result sent to driver
44026 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 1.0 (TID 140, localhost, ANY, 1489 bytes)
44026 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 57.0 in stage 1.0 (TID 140)
44030 [Executor task launch worker-0] INFO org.apache.spark.rdd.NewHadoopRDD - Input split: hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16/2015-06-11-16--vtqaana-cloudera03.dealer.ddc-RTBPixallHit.1434041950652.avro:0+1788
44030 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 1.0 (TID 137) in 507 ms on localhost (56/58)
44030 [Executor task launch worker-0] WARN org.apache.avro.mapreduce.AvroKeyInputFormat - Reader schema was not set. Use AvroJob.setInputKeySchema() if desired.
44030 [Executor task launch worker-0] INFO org.apache.avro.mapreduce.AvroKeyInputFormat - Using a reader schema equal to the writer schema.
44062 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 56.0 in stage 1.0 (TID 139). 2043 bytes result sent to driver
44067 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 1.0 (TID 139) in 332 ms on localhost (57/58)
44177 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 57.0 in stage 1.0 (TID 140). 2043 bytes result sent to driver
44181 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 1.0 (TID 140) in 153 ms on localhost (58/58)
44181 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Stage 1 (groupBy at RddHelper.scala:18) finished in 30.909 s
44181 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
44181 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - running: Set()
44181 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool
44181 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - waiting: Set(Stage 2, Stage 3)
44181 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - failed: Set()
44185 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
44197 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents for Stage 3: List(Stage 2)
44200 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting Stage 2 (MapPartitionsRDD[85] at map at ViewThroughCorrelation.scala:91), which is now runnable
44205 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(5088) called with curMem=9037896, maxMem=833492090
44205 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_30 stored as values in memory (estimated size 5.0 KB, free 786.3 MB)
44212 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(2527) called with curMem=9042984, maxMem=833492090
44212 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.5 KB, free 786.3 MB)
44213 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_30_piece0 in memory on localhost:60336 (size: 2.5 KB, free: 794.3 MB)
44213 [dag-scheduler-event-loop] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_30_piece0
44214 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:839
44217 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 58 missing tasks from Stage 2 (MapPartitionsRDD[85] at map at ViewThroughCorrelation.scala:91)
44218 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 58 tasks
44221 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 141, localhost, PROCESS_LOCAL, 1113 bytes)
44221 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 142, localhost, PROCESS_LOCAL, 1113 bytes)
44221 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 141)
44221 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 142)
44241 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44241 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44243 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 6 ms
44243 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 6 ms
44415 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 141). 1107 bytes result sent to driver
44416 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 2.0 (TID 143, localhost, PROCESS_LOCAL, 1113 bytes)
44416 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 2.0 in stage 2.0 (TID 143)
44420 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 141) in 197 ms on localhost (1/58)
44420 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44420 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
44581 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 2.0 in stage 2.0 (TID 143). 1107 bytes result sent to driver
44582 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 2.0 (TID 144, localhost, PROCESS_LOCAL, 1113 bytes)
44583 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 3.0 in stage 2.0 (TID 144)
44586 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 2.0 (TID 143) in 167 ms on localhost (2/58)
44588 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44588 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
44613 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 142). 1107 bytes result sent to driver
44614 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 2.0 (TID 145, localhost, PROCESS_LOCAL, 1113 bytes)
44614 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 4.0 in stage 2.0 (TID 145)
44616 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 142) in 393 ms on localhost (3/58)
44617 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44617 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
44736 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 4.0 in stage 2.0 (TID 145). 1107 bytes result sent to driver
44737 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 2.0 (TID 146, localhost, PROCESS_LOCAL, 1113 bytes)
44738 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 5.0 in stage 2.0 (TID 146)
44740 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 2.0 (TID 145) in 125 ms on localhost (4/58)
44740 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44740 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
44930 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 3.0 in stage 2.0 (TID 144). 1107 bytes result sent to driver
44931 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 2.0 (TID 147, localhost, PROCESS_LOCAL, 1113 bytes)
44931 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 6.0 in stage 2.0 (TID 147)
44933 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 2.0 (TID 144) in 349 ms on localhost (5/58)
44935 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
44935 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45048 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 5.0 in stage 2.0 (TID 146). 1107 bytes result sent to driver
45049 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 2.0 (TID 148, localhost, PROCESS_LOCAL, 1113 bytes)
45049 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 7.0 in stage 2.0 (TID 148)
45052 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 2.0 (TID 146) in 312 ms on localhost (6/58)
45052 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45052 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45071 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 6.0 in stage 2.0 (TID 147). 1107 bytes result sent to driver
45072 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 2.0 (TID 149, localhost, PROCESS_LOCAL, 1113 bytes)
45072 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 8.0 in stage 2.0 (TID 149)
45075 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45075 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45076 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 2.0 (TID 147) in 142 ms on localhost (7/58)
45172 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 7.0 in stage 2.0 (TID 148). 1107 bytes result sent to driver
45173 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 2.0 (TID 150, localhost, PROCESS_LOCAL, 1113 bytes)
45173 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 9.0 in stage 2.0 (TID 150)
45176 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 2.0 (TID 148) in 124 ms on localhost (8/58)
45176 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45176 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45386 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 8.0 in stage 2.0 (TID 149). 1107 bytes result sent to driver
45387 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 2.0 (TID 151, localhost, PROCESS_LOCAL, 1113 bytes)
45387 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 10.0 in stage 2.0 (TID 151)
45390 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45390 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45390 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 2.0 (TID 149) in 316 ms on localhost (9/58)
45456 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 9.0 in stage 2.0 (TID 150). 1107 bytes result sent to driver
45457 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 2.0 (TID 152, localhost, PROCESS_LOCAL, 1113 bytes)
45458 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 11.0 in stage 2.0 (TID 152)
45460 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45460 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45461 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 2.0 (TID 150) in 286 ms on localhost (10/58)
45785 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 10.0 in stage 2.0 (TID 151). 1107 bytes result sent to driver
45786 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 2.0 (TID 153, localhost, PROCESS_LOCAL, 1113 bytes)
45787 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 12.0 in stage 2.0 (TID 153)
45789 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 2.0 (TID 151) in 400 ms on localhost (11/58)
45789 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45789 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
45828 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 11.0 in stage 2.0 (TID 152). 1107 bytes result sent to driver
45829 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 2.0 (TID 154, localhost, PROCESS_LOCAL, 1113 bytes)
45830 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 13.0 in stage 2.0 (TID 154)
45833 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 2.0 (TID 152) in 372 ms on localhost (12/58)
45834 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
45834 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
46112 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 12.0 in stage 2.0 (TID 153). 1107 bytes result sent to driver
46113 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 2.0 (TID 155, localhost, PROCESS_LOCAL, 1113 bytes)
46113 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 14.0 in stage 2.0 (TID 155)
46115 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 2.0 (TID 153) in 327 ms on localhost (13/58)
46116 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46116 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
46188 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 13.0 in stage 2.0 (TID 154). 1107 bytes result sent to driver
46189 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 2.0 (TID 156, localhost, PROCESS_LOCAL, 1113 bytes)
46189 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 15.0 in stage 2.0 (TID 156)
46193 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 2.0 (TID 154) in 360 ms on localhost (14/58)
46194 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46194 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
46310 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 15.0 in stage 2.0 (TID 156). 1107 bytes result sent to driver
46311 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 2.0 (TID 157, localhost, PROCESS_LOCAL, 1113 bytes)
46312 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 16.0 in stage 2.0 (TID 157)
46314 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46314 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
46315 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 2.0 (TID 156) in 123 ms on localhost (15/58)
46406 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 14.0 in stage 2.0 (TID 155). 1107 bytes result sent to driver
46407 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 2.0 (TID 158, localhost, PROCESS_LOCAL, 1113 bytes)
46408 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 17.0 in stage 2.0 (TID 158)
46410 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46410 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
46411 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 2.0 (TID 155) in 296 ms on localhost (16/58)
46549 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 17.0 in stage 2.0 (TID 158). 1107 bytes result sent to driver
46550 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 2.0 (TID 159, localhost, PROCESS_LOCAL, 1113 bytes)
46550 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 18.0 in stage 2.0 (TID 159)
46552 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 2.0 (TID 158) in 143 ms on localhost (17/58)
46553 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46553 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
46651 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 16.0 in stage 2.0 (TID 157). 1107 bytes result sent to driver
46652 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 2.0 (TID 160, localhost, PROCESS_LOCAL, 1113 bytes)
46652 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 19.0 in stage 2.0 (TID 160)
46655 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46656 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
46656 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 2.0 (TID 157) in 341 ms on localhost (18/58)
46834 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 18.0 in stage 2.0 (TID 159). 1107 bytes result sent to driver
46844 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 2.0 (TID 161, localhost, PROCESS_LOCAL, 1113 bytes)
46844 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 20.0 in stage 2.0 (TID 161)
46847 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 2.0 (TID 159) in 295 ms on localhost (19/58)
46848 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
46848 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47033 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 20.0 in stage 2.0 (TID 161). 1107 bytes result sent to driver
47033 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 2.0 (TID 162, localhost, PROCESS_LOCAL, 1113 bytes)
47034 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 21.0 in stage 2.0 (TID 162)
47036 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47036 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47037 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 2.0 (TID 161) in 191 ms on localhost (20/58)
47059 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 19.0 in stage 2.0 (TID 160). 1107 bytes result sent to driver
47060 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 2.0 (TID 163, localhost, PROCESS_LOCAL, 1113 bytes)
47060 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 22.0 in stage 2.0 (TID 163)
47064 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47064 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47064 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 2.0 (TID 160) in 409 ms on localhost (21/58)
47197 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 22.0 in stage 2.0 (TID 163). 1107 bytes result sent to driver
47198 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 2.0 (TID 164, localhost, PROCESS_LOCAL, 1113 bytes)
47199 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 23.0 in stage 2.0 (TID 164)
47202 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47202 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47202 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 2.0 (TID 163) in 138 ms on localhost (22/58)
47364 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 23.0 in stage 2.0 (TID 164). 1107 bytes result sent to driver
47365 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 2.0 (TID 165, localhost, PROCESS_LOCAL, 1113 bytes)
47365 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 24.0 in stage 2.0 (TID 165)
47369 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 2.0 (TID 164) in 167 ms on localhost (23/58)
47369 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47369 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47399 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 21.0 in stage 2.0 (TID 162). 1107 bytes result sent to driver
47400 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 2.0 (TID 166, localhost, PROCESS_LOCAL, 1113 bytes)
47400 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 25.0 in stage 2.0 (TID 166)
47403 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 2.0 (TID 162) in 367 ms on localhost (24/58)
47404 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47404 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47530 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 24.0 in stage 2.0 (TID 165). 1107 bytes result sent to driver
47532 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 2.0 (TID 167, localhost, PROCESS_LOCAL, 1113 bytes)
47532 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 26.0 in stage 2.0 (TID 167)
47535 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 2.0 (TID 165) in 167 ms on localhost (25/58)
47536 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47536 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47784 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 25.0 in stage 2.0 (TID 166). 1107 bytes result sent to driver
47786 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 2.0 (TID 168, localhost, PROCESS_LOCAL, 1113 bytes)
47786 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 27.0 in stage 2.0 (TID 168)
47788 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47788 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47789 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 2.0 (TID 166) in 387 ms on localhost (26/58)
47846 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 26.0 in stage 2.0 (TID 167). 1107 bytes result sent to driver
47847 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 2.0 (TID 169, localhost, PROCESS_LOCAL, 1113 bytes)
47847 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 28.0 in stage 2.0 (TID 169)
47851 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 2.0 (TID 167) in 316 ms on localhost (27/58)
47851 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47851 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
47991 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 28.0 in stage 2.0 (TID 169). 1107 bytes result sent to driver
47992 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 2.0 (TID 170, localhost, PROCESS_LOCAL, 1113 bytes)
47993 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 29.0 in stage 2.0 (TID 170)
47995 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 2.0 (TID 169) in 146 ms on localhost (28/58)
47996 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
47996 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
48136 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 27.0 in stage 2.0 (TID 168). 1107 bytes result sent to driver
48137 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 2.0 (TID 171, localhost, PROCESS_LOCAL, 1113 bytes)
48137 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 30.0 in stage 2.0 (TID 171)
48139 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48140 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
48140 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 2.0 (TID 168) in 352 ms on localhost (29/58)
48428 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 29.0 in stage 2.0 (TID 170). 1107 bytes result sent to driver
48430 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 2.0 (TID 172, localhost, PROCESS_LOCAL, 1113 bytes)
48430 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 31.0 in stage 2.0 (TID 172)
48434 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 2.0 (TID 170) in 438 ms on localhost (30/58)
48434 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48434 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
48530 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 30.0 in stage 2.0 (TID 171). 1107 bytes result sent to driver
48532 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 2.0 (TID 173, localhost, PROCESS_LOCAL, 1113 bytes)
48532 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 32.0 in stage 2.0 (TID 173)
48536 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 2.0 (TID 171) in 396 ms on localhost (31/58)
48536 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48536 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
48577 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 31.0 in stage 2.0 (TID 172). 1107 bytes result sent to driver
48578 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 2.0 (TID 174, localhost, PROCESS_LOCAL, 1113 bytes)
48578 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 33.0 in stage 2.0 (TID 174)
48581 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48581 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
48582 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 2.0 (TID 172) in 149 ms on localhost (32/58)
48763 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 33.0 in stage 2.0 (TID 174). 1107 bytes result sent to driver
48765 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 2.0 (TID 175, localhost, PROCESS_LOCAL, 1113 bytes)
48769 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 2.0 (TID 174) in 188 ms on localhost (33/58)
48773 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 34.0 in stage 2.0 (TID 175)
48776 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48776 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
48928 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 34.0 in stage 2.0 (TID 175). 1107 bytes result sent to driver
48930 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 2.0 (TID 176, localhost, PROCESS_LOCAL, 1113 bytes)
48930 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 35.0 in stage 2.0 (TID 176)
48934 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 2.0 (TID 175) in 166 ms on localhost (34/58)
48934 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
48934 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
49065 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 32.0 in stage 2.0 (TID 173). 1107 bytes result sent to driver
49066 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 2.0 (TID 177, localhost, PROCESS_LOCAL, 1113 bytes)
49066 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 36.0 in stage 2.0 (TID 177)
49070 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
49070 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 2.0 (TID 173) in 535 ms on localhost (35/58)
49070 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
49309 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 35.0 in stage 2.0 (TID 176). 1107 bytes result sent to driver
49310 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 2.0 (TID 178, localhost, PROCESS_LOCAL, 1113 bytes)
49310 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 37.0 in stage 2.0 (TID 178)
49312 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 2.0 (TID 176) in 381 ms on localhost (36/58)
49314 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
49314 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
49438 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 36.0 in stage 2.0 (TID 177). 1107 bytes result sent to driver
49439 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 2.0 (TID 179, localhost, PROCESS_LOCAL, 1113 bytes)
49439 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 38.0 in stage 2.0 (TID 179)
49442 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 2.0 (TID 177) in 373 ms on localhost (37/58)
49443 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
49443 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
49478 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 37.0 in stage 2.0 (TID 178). 1107 bytes result sent to driver
49479 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 2.0 (TID 180, localhost, PROCESS_LOCAL, 1113 bytes)
49480 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 39.0 in stage 2.0 (TID 180)
49482 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 2.0 (TID 178) in 171 ms on localhost (38/58)
49484 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
49484 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
49885 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 38.0 in stage 2.0 (TID 179). 1107 bytes result sent to driver
49886 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 2.0 (TID 181, localhost, PROCESS_LOCAL, 1113 bytes)
49887 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 40.0 in stage 2.0 (TID 181)
49888 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 2.0 (TID 179) in 448 ms on localhost (39/58)
49892 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
49892 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
49997 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 39.0 in stage 2.0 (TID 180). 1107 bytes result sent to driver
49998 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 2.0 (TID 182, localhost, PROCESS_LOCAL, 1113 bytes)
49998 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 41.0 in stage 2.0 (TID 182)
50001 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
50001 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
50002 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 2.0 (TID 180) in 519 ms on localhost (40/58)
50064 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 40.0 in stage 2.0 (TID 181). 1107 bytes result sent to driver
50065 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 2.0 (TID 183, localhost, PROCESS_LOCAL, 1113 bytes)
50066 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 42.0 in stage 2.0 (TID 183)
50068 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 2.0 (TID 181) in 180 ms on localhost (41/58)
50069 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
50069 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
50796 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 42.0 in stage 2.0 (TID 183). 1107 bytes result sent to driver
50798 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 2.0 (TID 184, localhost, PROCESS_LOCAL, 1113 bytes)
50798 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 43.0 in stage 2.0 (TID 184)
50802 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 2.0 (TID 183) in 733 ms on localhost (42/58)
50803 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
50803 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
50843 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 41.0 in stage 2.0 (TID 182). 1107 bytes result sent to driver
50845 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 2.0 (TID 185, localhost, PROCESS_LOCAL, 1113 bytes)
50845 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 44.0 in stage 2.0 (TID 185)
50848 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 2.0 (TID 182) in 848 ms on localhost (43/58)
50849 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
50849 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
51270 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 44.0 in stage 2.0 (TID 185). 1107 bytes result sent to driver
51271 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 2.0 (TID 186, localhost, PROCESS_LOCAL, 1113 bytes)
51272 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 45.0 in stage 2.0 (TID 186)
51276 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 2.0 (TID 185) in 427 ms on localhost (44/58)
51276 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
51276 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
51331 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 43.0 in stage 2.0 (TID 184). 1107 bytes result sent to driver
51332 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 2.0 (TID 187, localhost, PROCESS_LOCAL, 1113 bytes)
51336 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 2.0 (TID 184) in 535 ms on localhost (45/58)
51336 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 46.0 in stage 2.0 (TID 187)
51341 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
51341 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
51544 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 46.0 in stage 2.0 (TID 187). 1107 bytes result sent to driver
51546 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 2.0 (TID 188, localhost, PROCESS_LOCAL, 1113 bytes)
51546 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 47.0 in stage 2.0 (TID 188)
51549 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 2.0 (TID 187) in 214 ms on localhost (46/58)
51550 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
51550 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
51714 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 45.0 in stage 2.0 (TID 186). 1107 bytes result sent to driver
51716 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 2.0 (TID 189, localhost, PROCESS_LOCAL, 1113 bytes)
51716 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 48.0 in stage 2.0 (TID 189)
51719 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 2.0 (TID 186) in 445 ms on localhost (47/58)
51720 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
51720 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
51755 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 47.0 in stage 2.0 (TID 188). 1107 bytes result sent to driver
51756 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 2.0 (TID 190, localhost, PROCESS_LOCAL, 1113 bytes)
51757 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 49.0 in stage 2.0 (TID 190)
51760 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 2.0 (TID 188) in 211 ms on localhost (48/58)
51762 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
51762 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
52143 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 48.0 in stage 2.0 (TID 189). 1107 bytes result sent to driver
52145 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 2.0 (TID 191, localhost, PROCESS_LOCAL, 1113 bytes)
52145 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 50.0 in stage 2.0 (TID 191)
52148 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
52148 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
52148 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 2.0 (TID 189) in 430 ms on localhost (49/58)
52298 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 49.0 in stage 2.0 (TID 190). 1107 bytes result sent to driver
52299 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 2.0 (TID 192, localhost, PROCESS_LOCAL, 1113 bytes)
52299 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 51.0 in stage 2.0 (TID 192)
52303 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 2.0 (TID 190) in 543 ms on localhost (50/58)
52304 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
52304 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
52338 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 50.0 in stage 2.0 (TID 191). 1107 bytes result sent to driver
52340 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 2.0 (TID 193, localhost, PROCESS_LOCAL, 1113 bytes)
52344 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 2.0 (TID 191) in 196 ms on localhost (51/58)
52344 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 52.0 in stage 2.0 (TID 193)
52348 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
52348 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
53265 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 51.0 in stage 2.0 (TID 192). 1107 bytes result sent to driver
53266 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 2.0 (TID 194, localhost, PROCESS_LOCAL, 1113 bytes)
53267 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 53.0 in stage 2.0 (TID 194)
53270 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 2.0 (TID 192) in 968 ms on localhost (52/58)
53270 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
53271 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
53350 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 52.0 in stage 2.0 (TID 193). 1107 bytes result sent to driver
53351 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 2.0 (TID 195, localhost, PROCESS_LOCAL, 1113 bytes)
53351 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 54.0 in stage 2.0 (TID 195)
53354 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 2.0 (TID 193) in 1012 ms on localhost (53/58)
53355 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
53355 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
53468 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 53.0 in stage 2.0 (TID 194). 1107 bytes result sent to driver
53469 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 2.0 (TID 196, localhost, PROCESS_LOCAL, 1113 bytes)
53469 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 55.0 in stage 2.0 (TID 196)
53473 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 2.0 (TID 194) in 203 ms on localhost (54/58)
53484 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
53485 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
53532 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 54.0 in stage 2.0 (TID 195). 1107 bytes result sent to driver
53533 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 2.0 (TID 197, localhost, PROCESS_LOCAL, 1113 bytes)
53533 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 56.0 in stage 2.0 (TID 197)
53537 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
53537 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 2.0 (TID 195) in 183 ms on localhost (55/58)
53537 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
53931 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 55.0 in stage 2.0 (TID 196). 1107 bytes result sent to driver
53932 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 2.0 (TID 198, localhost, PROCESS_LOCAL, 1113 bytes)
53932 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 57.0 in stage 2.0 (TID 198)
53936 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 2.0 (TID 196) in 464 ms on localhost (56/58)
53936 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 58 non-empty blocks out of 58 blocks
53936 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
54070 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 56.0 in stage 2.0 (TID 197). 1107 bytes result sent to driver
54076 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 2.0 (TID 197) in 540 ms on localhost (57/58)
54333 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 57.0 in stage 2.0 (TID 198). 1107 bytes result sent to driver
54337 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 2.0 (TID 198) in 403 ms on localhost (58/58)
54337 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool
54338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Stage 2 (map at ViewThroughCorrelation.scala:91) finished in 10.120 s
54338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
54338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - running: Set()
54338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - waiting: Set(Stage 3)
54338 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - failed: Set()
54351 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents for Stage 3: List()
54351 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting Stage 3 (MapPartitionsRDD[95] at map at ViewThroughCorrelation.scala:156), which is now runnable
54364 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(78768) called with curMem=9045511, maxMem=833492090
54365 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_31 stored as values in memory (estimated size 76.9 KB, free 786.2 MB)
54369 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(27246) called with curMem=9124279, maxMem=833492090
54369 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 26.6 KB, free 786.2 MB)
54370 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_31_piece0 in memory on localhost:60336 (size: 26.6 KB, free: 794.3 MB)
54370 [dag-scheduler-event-loop] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_31_piece0
54370 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:839
54376 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 83 missing tasks from Stage 3 (MapPartitionsRDD[95] at map at ViewThroughCorrelation.scala:156)
54377 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 83 tasks
54380 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 199, localhost, PROCESS_LOCAL, 1970 bytes)
54381 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 3.0 (TID 200, localhost, PROCESS_LOCAL, 1970 bytes)
54381 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 200)
54381 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 199)
54459 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
54459 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
54466 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
54466 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
54473 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
54473 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
54476 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
54477 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
55286 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
55307 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
55646 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000001_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000001
55650 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000000_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000000
55652 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 200). 1786 bytes result sent to driver
55653 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 3.0 (TID 201, localhost, PROCESS_LOCAL, 1970 bytes)
55653 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 2.0 in stage 3.0 (TID 201)
55654 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 199). 1786 bytes result sent to driver
55657 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 3.0 (TID 200) in 1273 ms on localhost (1/83)
55658 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 3.0 (TID 202, localhost, PROCESS_LOCAL, 1970 bytes)
55659 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 3.0 in stage 3.0 (TID 202)
55662 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 199) in 1282 ms on localhost (2/83)
55735 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
55736 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
55744 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
55744 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
55751 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
55751 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
55758 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
55758 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
56427 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
56427 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
56627 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000002_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000002
56632 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 2.0 in stage 3.0 (TID 201). 1800 bytes result sent to driver
56633 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 3.0 (TID 203, localhost, PROCESS_LOCAL, 1970 bytes)
56633 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 4.0 in stage 3.0 (TID 203)
56637 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 3.0 (TID 201) in 981 ms on localhost (3/83)
56643 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000003_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000003
56648 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 3.0 in stage 3.0 (TID 202). 1800 bytes result sent to driver
56650 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 3.0 (TID 204, localhost, PROCESS_LOCAL, 1970 bytes)
56650 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 5.0 in stage 3.0 (TID 204)
56655 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 3.0 (TID 202) in 992 ms on localhost (4/83)
56723 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
56724 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
56730 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
56730 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
56743 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
56743 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
56749 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
56749 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
57221 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
57236 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
57351 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000005_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000005
57356 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 5.0 in stage 3.0 (TID 204). 1800 bytes result sent to driver
57357 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 3.0 (TID 205, localhost, PROCESS_LOCAL, 1970 bytes)
57358 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 6.0 in stage 3.0 (TID 205)
57360 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 3.0 (TID 204) in 709 ms on localhost (5/83)
57368 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000004_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000004
57372 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 4.0 in stage 3.0 (TID 203). 1800 bytes result sent to driver
57373 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 3.0 (TID 206, localhost, PROCESS_LOCAL, 1970 bytes)
57374 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 7.0 in stage 3.0 (TID 206)
57377 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 3.0 (TID 203) in 742 ms on localhost (6/83)
57459 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
57460 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
57469 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
57469 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
57473 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
57473 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
57477 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
57477 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
58057 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
58064 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
58184 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000006_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000006
58189 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 6.0 in stage 3.0 (TID 205). 1800 bytes result sent to driver
58190 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 3.0 (TID 207, localhost, PROCESS_LOCAL, 1970 bytes)
58190 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 8.0 in stage 3.0 (TID 207)
58193 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 3.0 (TID 205) in 833 ms on localhost (7/83)
58234 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000007_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000007
58237 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 7.0 in stage 3.0 (TID 206). 1800 bytes result sent to driver
58238 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 3.0 (TID 208, localhost, PROCESS_LOCAL, 1970 bytes)
58238 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 9.0 in stage 3.0 (TID 208)
58242 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 3.0 (TID 206) in 865 ms on localhost (8/83)
58243 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
58243 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
58253 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
58253 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
58286 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
58286 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
58292 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
58292 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
58941 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
58958 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
59101 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000008_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000008
59105 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 8.0 in stage 3.0 (TID 207). 1800 bytes result sent to driver
59106 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 3.0 (TID 209, localhost, PROCESS_LOCAL, 1970 bytes)
59110 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 3.0 (TID 207) in 917 ms on localhost (9/83)
59110 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 10.0 in stage 3.0 (TID 209)
59118 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000009_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000009
59122 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 9.0 in stage 3.0 (TID 208). 1800 bytes result sent to driver
59124 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 3.0 (TID 210, localhost, PROCESS_LOCAL, 1970 bytes)
59124 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 11.0 in stage 3.0 (TID 210)
59127 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 3.0 (TID 208) in 887 ms on localhost (10/83)
59160 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
59161 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
59169 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
59169 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
59170 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
59170 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
59175 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
59175 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
59861 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
59872 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
60017 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000011_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000011
60017 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000010_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000010
60021 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 11.0 in stage 3.0 (TID 210). 1800 bytes result sent to driver
60023 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 3.0 (TID 211, localhost, PROCESS_LOCAL, 1970 bytes)
60023 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 12.0 in stage 3.0 (TID 211)
60027 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 3.0 (TID 210) in 900 ms on localhost (11/83)
60021 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 10.0 in stage 3.0 (TID 209). 1800 bytes result sent to driver
60029 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 3.0 (TID 212, localhost, PROCESS_LOCAL, 1970 bytes)
60029 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 13.0 in stage 3.0 (TID 212)
60033 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 3.0 (TID 209) in 924 ms on localhost (12/83)
60078 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
60078 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
60088 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
60088 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
60101 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
60101 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
60107 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
60107 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
60785 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
60785 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
60925 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000013_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000013
60928 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 13.0 in stage 3.0 (TID 212). 1800 bytes result sent to driver
60929 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 3.0 (TID 213, localhost, PROCESS_LOCAL, 1970 bytes)
60929 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 14.0 in stage 3.0 (TID 213)
60933 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 3.0 (TID 212) in 901 ms on localhost (13/83)
60942 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000012_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000012
60955 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 12.0 in stage 3.0 (TID 211). 1800 bytes result sent to driver
60956 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 3.0 (TID 214, localhost, PROCESS_LOCAL, 1970 bytes)
60956 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 15.0 in stage 3.0 (TID 214)
60960 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 3.0 (TID 211) in 934 ms on localhost (14/83)
60990 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
60990 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
60996 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
60996 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
60999 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
60999 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
61003 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
61003 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
61674 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
61690 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
61817 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000015_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000015
61821 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 15.0 in stage 3.0 (TID 214). 1800 bytes result sent to driver
61822 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 3.0 (TID 215, localhost, PROCESS_LOCAL, 1970 bytes)
61823 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 16.0 in stage 3.0 (TID 215)
61826 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 3.0 (TID 214) in 868 ms on localhost (15/83)
61833 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000014_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000014
61838 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 14.0 in stage 3.0 (TID 213). 1800 bytes result sent to driver
61839 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 3.0 (TID 216, localhost, PROCESS_LOCAL, 1970 bytes)
61840 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 17.0 in stage 3.0 (TID 216)
61843 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 3.0 (TID 213) in 911 ms on localhost (16/83)
61863 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
61864 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
61874 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
61874 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
61882 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
61882 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
61887 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
61887 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
62577 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
62679 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
62733 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000017_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000017
62737 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 17.0 in stage 3.0 (TID 216). 1800 bytes result sent to driver
62738 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 3.0 (TID 217, localhost, PROCESS_LOCAL, 1970 bytes)
62738 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 18.0 in stage 3.0 (TID 217)
62742 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 3.0 (TID 216) in 899 ms on localhost (17/83)
62800 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
62800 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
62809 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
62809 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
62850 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000016_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000016
62854 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 16.0 in stage 3.0 (TID 215). 1800 bytes result sent to driver
62855 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 3.0 (TID 218, localhost, PROCESS_LOCAL, 1970 bytes)
62859 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 3.0 (TID 215) in 1033 ms on localhost (18/83)
62859 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 19.0 in stage 3.0 (TID 218)
62899 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
62899 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
62904 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
62904 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
63460 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
63574 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
63583 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000018_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000018
63587 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 18.0 in stage 3.0 (TID 217). 1800 bytes result sent to driver
63588 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 3.0 (TID 219, localhost, PROCESS_LOCAL, 1970 bytes)
63589 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 20.0 in stage 3.0 (TID 219)
63592 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 3.0 (TID 217) in 851 ms on localhost (19/83)
63633 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
63633 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
63642 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
63642 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
63691 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000019_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000019
63695 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 19.0 in stage 3.0 (TID 218). 1800 bytes result sent to driver
63696 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 3.0 (TID 220, localhost, PROCESS_LOCAL, 1970 bytes)
63700 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 3.0 (TID 218) in 842 ms on localhost (20/83)
63701 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 21.0 in stage 3.0 (TID 220)
63762 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
63762 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
63767 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
63767 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
64542 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
64604 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
64689 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000021_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000021
64694 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 21.0 in stage 3.0 (TID 220). 1800 bytes result sent to driver
64695 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 3.0 (TID 221, localhost, PROCESS_LOCAL, 1970 bytes)
64695 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 22.0 in stage 3.0 (TID 221)
64699 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 3.0 (TID 220) in 999 ms on localhost (21/83)
64774 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000020_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000020
64776 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
64776 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
64778 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 20.0 in stage 3.0 (TID 219). 1800 bytes result sent to driver
64779 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 3.0 (TID 222, localhost, PROCESS_LOCAL, 1970 bytes)
64779 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 23.0 in stage 3.0 (TID 222)
64783 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 3.0 (TID 219) in 1191 ms on localhost (22/83)
64785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
64785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
64830 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
64830 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
64834 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
64834 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
65497 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
65503 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
65682 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000022_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000022
65687 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 22.0 in stage 3.0 (TID 221). 1800 bytes result sent to driver
65688 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 3.0 (TID 223, localhost, PROCESS_LOCAL, 1970 bytes)
65688 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 24.0 in stage 3.0 (TID 223)
65695 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 3.0 (TID 221) in 996 ms on localhost (23/83)
65707 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000023_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000023
65712 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 23.0 in stage 3.0 (TID 222). 1800 bytes result sent to driver
65713 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 3.0 (TID 224, localhost, PROCESS_LOCAL, 1970 bytes)
65713 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 25.0 in stage 3.0 (TID 224)
65718 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 3.0 (TID 222) in 935 ms on localhost (24/83)
65752 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
65752 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
65762 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
65762 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
65768 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
65768 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
65773 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
65773 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
66390 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
66431 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
66590 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000024_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000024
66594 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 24.0 in stage 3.0 (TID 223). 1800 bytes result sent to driver
66595 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 3.0 (TID 225, localhost, PROCESS_LOCAL, 1970 bytes)
66595 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 26.0 in stage 3.0 (TID 225)
66597 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 3.0 (TID 223) in 908 ms on localhost (25/83)
66623 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000025_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000025
66624 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
66624 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
66627 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 25.0 in stage 3.0 (TID 224). 1800 bytes result sent to driver
66628 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 3.0 (TID 226, localhost, PROCESS_LOCAL, 1970 bytes)
66629 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 27.0 in stage 3.0 (TID 226)
66630 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 3.0 (TID 224) in 917 ms on localhost (26/83)
66633 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
66633 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
66657 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
66657 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
66660 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
66660 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67058 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
67066 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
67182 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000026_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000026
67184 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 26.0 in stage 3.0 (TID 225). 1800 bytes result sent to driver
67185 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 3.0 (TID 227, localhost, PROCESS_LOCAL, 1970 bytes)
67185 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 28.0 in stage 3.0 (TID 227)
67189 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 3.0 (TID 225) in 591 ms on localhost (27/83)
67198 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000027_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000027
67203 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 27.0 in stage 3.0 (TID 226). 1800 bytes result sent to driver
67204 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 3.0 (TID 228, localhost, PROCESS_LOCAL, 1970 bytes)
67205 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 29.0 in stage 3.0 (TID 228)
67209 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 3.0 (TID 226) in 577 ms on localhost (28/83)
67209 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
67209 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67215 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
67215 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67227 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
67227 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
67230 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
67230 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67600 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
67610 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
67723 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000028_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000028
67727 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 28.0 in stage 3.0 (TID 227). 1800 bytes result sent to driver
67728 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 3.0 (TID 229, localhost, PROCESS_LOCAL, 1970 bytes)
67728 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 30.0 in stage 3.0 (TID 229)
67732 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 3.0 (TID 227) in 544 ms on localhost (29/83)
67740 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000029_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000029
67742 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 29.0 in stage 3.0 (TID 228). 1800 bytes result sent to driver
67743 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 3.0 (TID 230, localhost, PROCESS_LOCAL, 1970 bytes)
67744 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 31.0 in stage 3.0 (TID 230)
67745 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 3.0 (TID 228) in 540 ms on localhost (30/83)
67771 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
67771 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67780 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
67780 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
67780 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67780 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
67784 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
67784 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68200 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
68217 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
68323 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000030_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000030
68327 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 30.0 in stage 3.0 (TID 229). 1800 bytes result sent to driver
68328 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 3.0 (TID 231, localhost, PROCESS_LOCAL, 1970 bytes)
68329 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 32.0 in stage 3.0 (TID 231)
68331 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 3.0 (TID 229) in 600 ms on localhost (31/83)
68359 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
68359 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68365 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
68365 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68406 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000031_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000031
68408 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 31.0 in stage 3.0 (TID 230). 1800 bytes result sent to driver
68409 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 3.0 (TID 232, localhost, PROCESS_LOCAL, 1970 bytes)
68410 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 33.0 in stage 3.0 (TID 232)
68412 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 3.0 (TID 230) in 666 ms on localhost (32/83)
68434 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
68434 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68437 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
68437 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68742 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
68793 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
68872 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000032_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000032
68876 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 32.0 in stage 3.0 (TID 231). 1800 bytes result sent to driver
68878 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 3.0 (TID 233, localhost, PROCESS_LOCAL, 1970 bytes)
68878 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 34.0 in stage 3.0 (TID 233)
68880 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 3.0 (TID 231) in 550 ms on localhost (33/83)
68909 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
68909 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68915 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
68915 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68922 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000033_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000033
68924 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 33.0 in stage 3.0 (TID 232). 1800 bytes result sent to driver
68926 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 3.0 (TID 234, localhost, PROCESS_LOCAL, 1970 bytes)
68926 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 35.0 in stage 3.0 (TID 234)
68928 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 3.0 (TID 232) in 517 ms on localhost (34/83)
68951 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
68951 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
68956 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
68956 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
69267 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
69282 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
69364 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000034_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000034
69368 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 34.0 in stage 3.0 (TID 233). 1800 bytes result sent to driver
69369 [sparkDriver-akka.actor.default-dispatcher-3] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 3.0 (TID 235, localhost, PROCESS_LOCAL, 1970 bytes)
69370 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 36.0 in stage 3.0 (TID 235)
69372 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 3.0 (TID 233) in 493 ms on localhost (35/83)
69399 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
69399 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
69405 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
69405 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
69414 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000035_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000035
69418 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 35.0 in stage 3.0 (TID 234). 1800 bytes result sent to driver
69419 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 3.0 (TID 236, localhost, PROCESS_LOCAL, 1970 bytes)
69420 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 37.0 in stage 3.0 (TID 236)
69424 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 3.0 (TID 234) in 495 ms on localhost (36/83)
69451 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
69451 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
69454 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
69454 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
69808 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
69821 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
69905 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000036_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000036
69908 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 36.0 in stage 3.0 (TID 235). 1800 bytes result sent to driver
69909 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 3.0 (TID 237, localhost, PROCESS_LOCAL, 1970 bytes)
69909 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 38.0 in stage 3.0 (TID 237)
69911 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 3.0 (TID 235) in 540 ms on localhost (37/83)
69935 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
69935 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
69941 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
69941 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
69955 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000037_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000037
69958 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 37.0 in stage 3.0 (TID 236). 1800 bytes result sent to driver
69960 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 3.0 (TID 238, localhost, PROCESS_LOCAL, 1970 bytes)
69960 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 39.0 in stage 3.0 (TID 238)
69962 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 3.0 (TID 236) in 541 ms on localhost (38/83)
70004 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
70004 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
70014 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
70014 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
70314 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
70388 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
70447 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000038_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000038
70451 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 38.0 in stage 3.0 (TID 237). 1800 bytes result sent to driver
70452 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 3.0 (TID 239, localhost, PROCESS_LOCAL, 1970 bytes)
70453 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 40.0 in stage 3.0 (TID 239)
70456 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 3.0 (TID 237) in 545 ms on localhost (39/83)
70479 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
70479 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
70485 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
70485 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
70505 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000039_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000039
70507 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 39.0 in stage 3.0 (TID 238). 1800 bytes result sent to driver
70509 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 3.0 (TID 240, localhost, PROCESS_LOCAL, 1970 bytes)
70509 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 41.0 in stage 3.0 (TID 240)
70513 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 3.0 (TID 238) in 551 ms on localhost (40/83)
70532 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
70532 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
70535 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
70535 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
70843 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
70891 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
70955 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000040_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000040
70957 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 40.0 in stage 3.0 (TID 239). 1800 bytes result sent to driver
70959 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 3.0 (TID 241, localhost, PROCESS_LOCAL, 1970 bytes)
70959 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 42.0 in stage 3.0 (TID 241)
70961 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 3.0 (TID 239) in 507 ms on localhost (41/83)
70983 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
70983 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
70988 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
70988 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
71005 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000041_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000041
71007 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 41.0 in stage 3.0 (TID 240). 1800 bytes result sent to driver
71008 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 3.0 (TID 242, localhost, PROCESS_LOCAL, 1970 bytes)
71008 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 43.0 in stage 3.0 (TID 242)
71010 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 3.0 (TID 240) in 500 ms on localhost (42/83)
71029 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
71030 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
71032 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
71032 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
71314 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
71349 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
71447 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000042_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000042
71449 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 42.0 in stage 3.0 (TID 241). 1800 bytes result sent to driver
71450 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 3.0 (TID 243, localhost, PROCESS_LOCAL, 1970 bytes)
71451 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 44.0 in stage 3.0 (TID 243)
71454 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 3.0 (TID 241) in 493 ms on localhost (43/83)
71475 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
71475 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
71481 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
71481 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
71513 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000043_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000043
71517 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 43.0 in stage 3.0 (TID 242). 1800 bytes result sent to driver
71518 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 3.0 (TID 244, localhost, PROCESS_LOCAL, 1970 bytes)
71519 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 45.0 in stage 3.0 (TID 244)
71522 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 3.0 (TID 242) in 512 ms on localhost (44/83)
71553 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
71553 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
71558 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
71558 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
71850 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
71887 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
72130 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000044_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000044
72134 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 44.0 in stage 3.0 (TID 243). 1800 bytes result sent to driver
72136 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 3.0 (TID 245, localhost, PROCESS_LOCAL, 1970 bytes)
72136 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 46.0 in stage 3.0 (TID 245)
72138 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 3.0 (TID 243) in 686 ms on localhost (45/83)
72147 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000045_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000045
72151 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 45.0 in stage 3.0 (TID 244). 1800 bytes result sent to driver
72152 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 3.0 (TID 246, localhost, PROCESS_LOCAL, 1970 bytes)
72152 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 47.0 in stage 3.0 (TID 246)
72154 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 3.0 (TID 244) in 634 ms on localhost (46/83)
72173 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
72173 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
72178 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
72178 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
72180 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
72180 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
72183 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
72183 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
72579 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
72603 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
72696 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000047_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000047
72699 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 47.0 in stage 3.0 (TID 246). 1800 bytes result sent to driver
72700 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 3.0 (TID 247, localhost, PROCESS_LOCAL, 1970 bytes)
72700 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 48.0 in stage 3.0 (TID 247)
72704 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 3.0 (TID 246) in 549 ms on localhost (47/83)
72738 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
72738 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
72743 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
72743 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
72746 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000046_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000046
72750 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 46.0 in stage 3.0 (TID 245). 1800 bytes result sent to driver
72751 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 3.0 (TID 248, localhost, PROCESS_LOCAL, 1970 bytes)
72751 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 49.0 in stage 3.0 (TID 248)
72754 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 3.0 (TID 245) in 616 ms on localhost (48/83)
72780 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
72780 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
72782 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
72782 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73082 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
73117 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
73196 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000048_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000048
73199 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 48.0 in stage 3.0 (TID 247). 1800 bytes result sent to driver
73199 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 3.0 (TID 249, localhost, PROCESS_LOCAL, 1970 bytes)
73200 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 50.0 in stage 3.0 (TID 249)
73202 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 3.0 (TID 247) in 501 ms on localhost (49/83)
73223 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000049_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000049
73227 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 49.0 in stage 3.0 (TID 248). 1800 bytes result sent to driver
73228 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 3.0 (TID 250, localhost, PROCESS_LOCAL, 1970 bytes)
73228 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 51.0 in stage 3.0 (TID 250)
73229 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
73230 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
73232 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 3.0 (TID 248) in 478 ms on localhost (50/83)
73238 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
73238 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73265 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
73265 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73270 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
73270 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
73647 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
73647 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
73771 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000051_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000051
73771 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000050_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000050
73775 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 51.0 in stage 3.0 (TID 250). 1800 bytes result sent to driver
73775 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 50.0 in stage 3.0 (TID 249). 1800 bytes result sent to driver
73776 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 3.0 (TID 251, localhost, PROCESS_LOCAL, 1970 bytes)
73776 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 52.0 in stage 3.0 (TID 251)
73780 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 3.0 (TID 249) in 577 ms on localhost (51/83)
73780 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 3.0 (TID 252, localhost, PROCESS_LOCAL, 1970 bytes)
73780 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 53.0 in stage 3.0 (TID 252)
73783 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 3.0 (TID 250) in 553 ms on localhost (52/83)
73818 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
73818 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
73818 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73818 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73824 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
73824 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
73824 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
73824 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
74210 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
74216 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
74338 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000053_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000053
74340 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 53.0 in stage 3.0 (TID 252). 1800 bytes result sent to driver
74341 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 3.0 (TID 253, localhost, PROCESS_LOCAL, 1970 bytes)
74342 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 54.0 in stage 3.0 (TID 253)
74345 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 3.0 (TID 252) in 562 ms on localhost (53/83)
74354 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000052_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000052
74357 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 52.0 in stage 3.0 (TID 251). 1800 bytes result sent to driver
74358 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 3.0 (TID 254, localhost, PROCESS_LOCAL, 1970 bytes)
74358 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 55.0 in stage 3.0 (TID 254)
74362 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 3.0 (TID 251) in 582 ms on localhost (54/83)
74366 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
74366 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
74372 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
74372 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
74392 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
74392 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
74395 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
74395 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
74908 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
74962 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
75029 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000055_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000055
75034 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 55.0 in stage 3.0 (TID 254). 1800 bytes result sent to driver
75035 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 3.0 (TID 255, localhost, PROCESS_LOCAL, 1970 bytes)
75035 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 56.0 in stage 3.0 (TID 255)
75039 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 3.0 (TID 254) in 678 ms on localhost (55/83)
75075 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
75075 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75079 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
75079 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75079 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000054_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000054
75083 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 54.0 in stage 3.0 (TID 253). 1800 bytes result sent to driver
75084 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 3.0 (TID 256, localhost, PROCESS_LOCAL, 1970 bytes)
75085 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 57.0 in stage 3.0 (TID 256)
75088 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 3.0 (TID 253) in 744 ms on localhost (56/83)
75123 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
75123 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75126 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
75126 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75591 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
75616 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
75738 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000056_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000056
75742 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 56.0 in stage 3.0 (TID 255). 1800 bytes result sent to driver
75743 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 3.0 (TID 257, localhost, PROCESS_LOCAL, 1970 bytes)
75743 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 58.0 in stage 3.0 (TID 257)
75747 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 3.0 (TID 255) in 709 ms on localhost (57/83)
75754 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000057_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000057
75758 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 57.0 in stage 3.0 (TID 256). 1800 bytes result sent to driver
75760 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 3.0 (TID 258, localhost, PROCESS_LOCAL, 1970 bytes)
75760 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 59.0 in stage 3.0 (TID 258)
75763 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 3.0 (TID 256) in 676 ms on localhost (58/83)
75788 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
75788 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75795 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
75795 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75798 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
75798 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
75801 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
75801 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
76319 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
76359 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
76470 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000059_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000059
76473 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 59.0 in stage 3.0 (TID 258). 1800 bytes result sent to driver
76474 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 3.0 (TID 259, localhost, PROCESS_LOCAL, 1970 bytes)
76474 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 60.0 in stage 3.0 (TID 259)
76476 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 3.0 (TID 258) in 715 ms on localhost (59/83)
76487 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000058_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000058
76491 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 58.0 in stage 3.0 (TID 257). 1800 bytes result sent to driver
76492 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 3.0 (TID 260, localhost, PROCESS_LOCAL, 1970 bytes)
76492 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 61.0 in stage 3.0 (TID 260)
76496 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 3.0 (TID 257) in 750 ms on localhost (60/83)
76497 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
76497 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
76502 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
76502 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
76513 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
76514 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
76516 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
76516 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
76841 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
76850 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
77012 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000061_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000061
77012 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000060_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000060
77015 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 61.0 in stage 3.0 (TID 260). 1800 bytes result sent to driver
77016 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 3.0 (TID 261, localhost, PROCESS_LOCAL, 1970 bytes)
77016 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 62.0 in stage 3.0 (TID 261)
77016 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 60.0 in stage 3.0 (TID 259). 1800 bytes result sent to driver
77018 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 3.0 (TID 260) in 525 ms on localhost (61/83)
77019 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 3.0 (TID 262, localhost, PROCESS_LOCAL, 1970 bytes)
77019 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 63.0 in stage 3.0 (TID 262)
77022 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 3.0 (TID 259) in 546 ms on localhost (62/83)
77048 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
77048 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77052 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
77052 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77053 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
77053 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77056 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
77056 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77495 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
77505 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
77612 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000062_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000062
77616 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 62.0 in stage 3.0 (TID 261). 1800 bytes result sent to driver
77617 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 3.0 (TID 263, localhost, PROCESS_LOCAL, 1970 bytes)
77617 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 64.0 in stage 3.0 (TID 263)
77621 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 3.0 (TID 261) in 602 ms on localhost (63/83)
77628 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000063_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000063
77633 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 63.0 in stage 3.0 (TID 262). 1800 bytes result sent to driver
77633 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 3.0 (TID 264, localhost, PROCESS_LOCAL, 1970 bytes)
77634 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 65.0 in stage 3.0 (TID 264)
77638 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 3.0 (TID 262) in 616 ms on localhost (64/83)
77656 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
77656 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77663 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
77663 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77668 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
77668 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
77670 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
77670 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78130 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
78136 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
78262 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000065_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000065
78266 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 65.0 in stage 3.0 (TID 264). 1800 bytes result sent to driver
78267 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 3.0 (TID 265, localhost, PROCESS_LOCAL, 1970 bytes)
78267 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 66.0 in stage 3.0 (TID 265)
78270 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 3.0 (TID 264) in 634 ms on localhost (65/83)
78278 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000064_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000064
78283 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 64.0 in stage 3.0 (TID 263). 1800 bytes result sent to driver
78284 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 3.0 (TID 266, localhost, PROCESS_LOCAL, 1970 bytes)
78284 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 67.0 in stage 3.0 (TID 266)
78287 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 3.0 (TID 263) in 668 ms on localhost (66/83)
78307 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
78307 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78308 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
78308 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
78312 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
78312 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78312 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
78312 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78740 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
78793 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
78869 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000067_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000067
78873 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 67.0 in stage 3.0 (TID 266). 1800 bytes result sent to driver
78874 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 3.0 (TID 267, localhost, PROCESS_LOCAL, 1970 bytes)
78874 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 68.0 in stage 3.0 (TID 267)
78877 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 3.0 (TID 266) in 591 ms on localhost (67/83)
78900 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
78900 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78905 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
78905 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78936 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000066_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000066
78940 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 66.0 in stage 3.0 (TID 265). 1800 bytes result sent to driver
78942 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 3.0 (TID 268, localhost, PROCESS_LOCAL, 1970 bytes)
78942 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 69.0 in stage 3.0 (TID 268)
78945 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 3.0 (TID 265) in 676 ms on localhost (68/83)
78984 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
78984 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
78988 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
78988 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
79363 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
79478 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000068_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000068
79481 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 68.0 in stage 3.0 (TID 267). 1800 bytes result sent to driver
79482 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 3.0 (TID 269, localhost, PROCESS_LOCAL, 1970 bytes)
79482 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 70.0 in stage 3.0 (TID 269)
79486 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 3.0 (TID 267) in 609 ms on localhost (69/83)
79498 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
79531 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
79531 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
79537 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
79537 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
79636 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000069_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000069
79639 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 69.0 in stage 3.0 (TID 268). 1800 bytes result sent to driver
79640 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 3.0 (TID 270, localhost, PROCESS_LOCAL, 1970 bytes)
79640 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 71.0 in stage 3.0 (TID 270)
79642 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 3.0 (TID 268) in 699 ms on localhost (70/83)
79662 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
79662 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
79664 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
79664 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
79936 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
80012 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
80069 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000070_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000070
80073 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 70.0 in stage 3.0 (TID 269). 1800 bytes result sent to driver
80074 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 3.0 (TID 271, localhost, PROCESS_LOCAL, 1970 bytes)
80074 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 72.0 in stage 3.0 (TID 271)
80078 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 3.0 (TID 269) in 592 ms on localhost (71/83)
80098 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
80098 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
80102 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
80102 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
80102 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000071_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000071
80106 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 71.0 in stage 3.0 (TID 270). 1800 bytes result sent to driver
80107 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 3.0 (TID 272, localhost, PROCESS_LOCAL, 1970 bytes)
80107 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 73.0 in stage 3.0 (TID 272)
80111 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 3.0 (TID 270) in 467 ms on localhost (72/83)
80134 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
80134 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
80135 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
80135 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
80493 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
80606 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
80919 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000073_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000073
80924 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 73.0 in stage 3.0 (TID 272). 1800 bytes result sent to driver
80925 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 3.0 (TID 273, localhost, PROCESS_LOCAL, 1970 bytes)
80925 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 74.0 in stage 3.0 (TID 273)
80929 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 3.0 (TID 272) in 818 ms on localhost (73/83)
80963 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
80963 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
80968 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
80968 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
80969 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000072_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000072
80971 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 72.0 in stage 3.0 (TID 271). 1800 bytes result sent to driver
80972 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 3.0 (TID 274, localhost, PROCESS_LOCAL, 1970 bytes)
80973 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 75.0 in stage 3.0 (TID 274)
80976 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 3.0 (TID 271) in 899 ms on localhost (74/83)
80994 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
80994 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
80996 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
80996 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
81420 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
81471 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
81602 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000075_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000075
81606 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 75.0 in stage 3.0 (TID 274). 1800 bytes result sent to driver
81608 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 3.0 (TID 275, localhost, PROCESS_LOCAL, 1970 bytes)
81608 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 76.0 in stage 3.0 (TID 275)
81611 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 3.0 (TID 274) in 636 ms on localhost (75/83)
81647 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
81647 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
81652 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000074_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000074
81654 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
81654 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
81656 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 74.0 in stage 3.0 (TID 273). 1800 bytes result sent to driver
81657 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 3.0 (TID 276, localhost, PROCESS_LOCAL, 1970 bytes)
81658 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 77.0 in stage 3.0 (TID 276)
81661 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 3.0 (TID 273) in 734 ms on localhost (76/83)
81696 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
81696 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
81699 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
81699 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82117 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
82189 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
82252 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000076_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000076
82254 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 76.0 in stage 3.0 (TID 275). 1800 bytes result sent to driver
82255 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 3.0 (TID 277, localhost, PROCESS_LOCAL, 1970 bytes)
82255 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 78.0 in stage 3.0 (TID 277)
82257 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 3.0 (TID 275) in 648 ms on localhost (77/83)
82278 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
82278 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82282 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
82282 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82302 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000077_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000077
82304 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 77.0 in stage 3.0 (TID 276). 1800 bytes result sent to driver
82305 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 3.0 (TID 278, localhost, PROCESS_LOCAL, 1970 bytes)
82305 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 79.0 in stage 3.0 (TID 278)
82307 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 3.0 (TID 276) in 648 ms on localhost (78/83)
82327 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
82327 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82329 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
82329 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82620 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
82687 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
82752 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000078_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000078
82755 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 78.0 in stage 3.0 (TID 277). 1800 bytes result sent to driver
82756 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 3.0 (TID 279, localhost, PROCESS_LOCAL, 1970 bytes)
82756 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 80.0 in stage 3.0 (TID 279)
82760 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 3.0 (TID 277) in 501 ms on localhost (79/83)
82784 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
82784 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
82788 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
82788 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82801 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000079_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000079
82804 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 79.0 in stage 3.0 (TID 278). 1800 bytes result sent to driver
82805 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 3.0 (TID 280, localhost, PROCESS_LOCAL, 1970 bytes)
82805 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 81.0 in stage 3.0 (TID 280)
82807 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 3.0 (TID 278) in 501 ms on localhost (80/83)
82826 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
82826 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
82828 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
82828 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
83159 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
83171 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
83276 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000081_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000081
83279 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 81.0 in stage 3.0 (TID 280). 1800 bytes result sent to driver
83279 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 3.0 (TID 281, localhost, PROCESS_LOCAL, 1970 bytes)
83280 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 82.0 in stage 3.0 (TID 281)
83282 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 3.0 (TID 280) in 476 ms on localhost (81/83)
83293 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000080_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000080
83295 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 80.0 in stage 3.0 (TID 279). 1800 bytes result sent to driver
83298 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 3.0 (TID 279) in 541 ms on localhost (82/83)
83302 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
83302 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
83306 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
83306 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
83806 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
84059 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121509_0095_r_000082_0' to hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16/_temporary/0/task_201506121509_0095_r_000082
84063 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 82.0 in stage 3.0 (TID 281). 1800 bytes result sent to driver
84068 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Stage 3 (saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156) finished in 29.691 s
84074 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 3.0 (TID 281) in 785 ms on localhost (83/83)
84074 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool
84079 [main] INFO org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156, took 71.566287 s
86121 [main] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
86171 [main] INFO org.apache.spark.SparkContext - Starting job: saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156
86183 [dag-scheduler-event-loop] INFO org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 3649 bytes
86204 [dag-scheduler-event-loop] INFO org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 2 is 386 bytes
86208 [dag-scheduler-event-loop] INFO org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 424 bytes
86211 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156) with 83 output partitions (allowLocal=false)
86211 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Final stage: Stage 7(saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156)
86211 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 6, Stage 4)
86223 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
86231 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting Stage 7 (MapPartitionsRDD[96] at map at ViewThroughCorrelation.scala:156), which has no missing parents
86249 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(78768) called with curMem=9151525, maxMem=833492090
86250 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_32 stored as values in memory (estimated size 76.9 KB, free 786.1 MB)
86255 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - ensureFreeSpace(27223) called with curMem=9230293, maxMem=833492090
86256 [dag-scheduler-event-loop] INFO org.apache.spark.storage.MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 26.6 KB, free 786.1 MB)
86256 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_32_piece0 in memory on localhost:60336 (size: 26.6 KB, free: 794.2 MB)
86256 [dag-scheduler-event-loop] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_32_piece0
86257 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:839
86265 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 83 missing tasks from Stage 7 (MapPartitionsRDD[96] at map at ViewThroughCorrelation.scala:156)
86265 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 83 tasks
86267 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 282, localhost, PROCESS_LOCAL, 1970 bytes)
86267 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 7.0 (TID 283, localhost, PROCESS_LOCAL, 1970 bytes)
86267 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 282)
86267 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 1.0 in stage 7.0 (TID 283)
86328 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
86328 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
86331 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
86331 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
86334 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
86335 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
86334 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
86338 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
87332 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing broadcast 31
87335 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_31
87335 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.MemoryStore - Block broadcast_31 of size 78768 dropped from memory (free 824313342)
87336 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_31_piece0
87336 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.MemoryStore - Block broadcast_31_piece0 of size 27246 dropped from memory (free 824340588)
87337 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManagerInfo - Removed broadcast_31_piece0 on localhost:60336 in memory (size: 26.6 KB, free: 794.3 MB)
87338 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_31_piece0
87359 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner - Cleaned broadcast 31
87360 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing broadcast 30
87361 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_30_piece0
87361 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.MemoryStore - Block broadcast_30_piece0 of size 2527 dropped from memory (free 824343115)
87362 [sparkDriver-akka.actor.default-dispatcher-2] INFO org.apache.spark.storage.BlockManagerInfo - Removed broadcast_30_piece0 on localhost:60336 in memory (size: 2.5 KB, free: 794.3 MB)
87362 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_30_piece0
87362 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_30
87362 [sparkDriver-akka.actor.default-dispatcher-4] INFO org.apache.spark.storage.MemoryStore - Block broadcast_30 of size 5088 dropped from memory (free 824348203)
87365 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner - Cleaned broadcast 30
87366 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManager - Removing broadcast 29
87366 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_29_piece0
87366 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.MemoryStore - Block broadcast_29_piece0 of size 2293 dropped from memory (free 824350496)
87367 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManagerInfo - Removed broadcast_29_piece0 on localhost:60336 in memory (size: 2.2 KB, free: 794.3 MB)
87367 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_29_piece0
87367 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_29
87367 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.MemoryStore - Block broadcast_29 of size 4376 dropped from memory (free 824354872)
87371 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner - Cleaned broadcast 29
87372 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManager - Removing broadcast 28
87372 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_28
87372 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.MemoryStore - Block broadcast_28 of size 11216 dropped from memory (free 824366088)
87372 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManager - Removing block broadcast_28_piece0
87372 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.MemoryStore - Block broadcast_28_piece0 of size 3631 dropped from memory (free 824369719)
87373 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.storage.BlockManagerInfo - Removed broadcast_28_piece0 on localhost:60336 in memory (size: 3.5 KB, free: 794.3 MB)
87373 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_28_piece0
87374 [Spark Context Cleaner] INFO org.apache.spark.ContextCleaner - Cleaned broadcast 28
87856 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
88050 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
88687 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000000_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000000
88691 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 282). 1800 bytes result sent to driver
88692 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 7.0 (TID 284, localhost, PROCESS_LOCAL, 1970 bytes)
88692 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 2.0 in stage 7.0 (TID 284)
88696 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 282) in 2426 ms on localhost (1/83)
88716 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000001_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000001
88721 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 1.0 in stage 7.0 (TID 283). 1800 bytes result sent to driver
88722 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 7.0 (TID 285, localhost, PROCESS_LOCAL, 1970 bytes)
88722 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 3.0 in stage 7.0 (TID 285)
88726 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 7.0 (TID 283) in 2455 ms on localhost (2/83)
88778 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
88778 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
88793 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
88793 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
88812 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
88812 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
88815 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
88815 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
89895 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
90116 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
90132 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000002_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000002
90136 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 2.0 in stage 7.0 (TID 284). 1800 bytes result sent to driver
90137 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 7.0 (TID 286, localhost, PROCESS_LOCAL, 1970 bytes)
90138 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 4.0 in stage 7.0 (TID 286)
90141 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 7.0 (TID 284) in 1446 ms on localhost (3/83)
90196 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
90196 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
90203 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
90203 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
90382 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000003_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000003
90385 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 3.0 in stage 7.0 (TID 285). 1800 bytes result sent to driver
90386 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 7.0 (TID 287, localhost, PROCESS_LOCAL, 1970 bytes)
90386 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 5.0 in stage 7.0 (TID 287)
90389 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 7.0 (TID 285) in 1666 ms on localhost (4/83)
90457 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
90457 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
90460 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
90460 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
91201 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
91406 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000004_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000004
91410 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 4.0 in stage 7.0 (TID 286). 1800 bytes result sent to driver
91411 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 7.0 (TID 288, localhost, PROCESS_LOCAL, 1970 bytes)
91411 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 6.0 in stage 7.0 (TID 288)
91415 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 7.0 (TID 286) in 1275 ms on localhost (5/83)
91427 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
91463 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
91463 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
91481 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
91482 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
91724 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000005_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000005
91728 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 5.0 in stage 7.0 (TID 287). 1800 bytes result sent to driver
91729 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 7.0 (TID 289, localhost, PROCESS_LOCAL, 1970 bytes)
91730 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 7.0 in stage 7.0 (TID 289)
91733 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 7.0 (TID 287) in 1345 ms on localhost (6/83)
91766 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
91766 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
91769 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
91769 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
92296 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
92537 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
92765 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000007_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000007
92770 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 7.0 in stage 7.0 (TID 289). 1800 bytes result sent to driver
92771 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 7.0 (TID 290, localhost, PROCESS_LOCAL, 1970 bytes)
92772 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 8.0 in stage 7.0 (TID 290)
92776 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 7.0 (TID 289) in 1042 ms on localhost (7/83)
92782 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000006_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000006
92786 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 6.0 in stage 7.0 (TID 288). 1800 bytes result sent to driver
92788 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 7.0 (TID 291, localhost, PROCESS_LOCAL, 1970 bytes)
92788 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 9.0 in stage 7.0 (TID 291)
92792 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 7.0 (TID 288) in 1377 ms on localhost (8/83)
92818 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
92818 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
92821 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
92821 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
92824 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
92824 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
92824 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
92824 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
93436 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
93449 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
93581 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000009_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000009
93586 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 9.0 in stage 7.0 (TID 291). 1800 bytes result sent to driver
93587 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 7.0 (TID 292, localhost, PROCESS_LOCAL, 1970 bytes)
93587 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 10.0 in stage 7.0 (TID 292)
93591 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 7.0 (TID 291) in 800 ms on localhost (9/83)
93612 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
93612 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
93616 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
93616 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
93631 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000008_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000008
93635 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 8.0 in stage 7.0 (TID 290). 1800 bytes result sent to driver
93637 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 7.0 (TID 293, localhost, PROCESS_LOCAL, 1970 bytes)
93637 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 11.0 in stage 7.0 (TID 293)
93640 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 7.0 (TID 290) in 866 ms on localhost (10/83)
93685 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
93685 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
93688 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
93688 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
94066 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
94248 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000010_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000010
94249 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
94252 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 10.0 in stage 7.0 (TID 292). 1800 bytes result sent to driver
94253 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 7.0 (TID 294, localhost, PROCESS_LOCAL, 1970 bytes)
94253 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 12.0 in stage 7.0 (TID 294)
94263 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 7.0 (TID 292) in 668 ms on localhost (11/83)
94295 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
94295 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
94302 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
94302 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
94531 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000011_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000011
94535 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 11.0 in stage 7.0 (TID 293). 1800 bytes result sent to driver
94537 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 7.0 (TID 295, localhost, PROCESS_LOCAL, 1970 bytes)
94541 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 7.0 (TID 293) in 902 ms on localhost (12/83)
94542 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 13.0 in stage 7.0 (TID 295)
94579 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
94579 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
94581 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
94581 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
95115 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
95314 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000012_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000012
95318 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 12.0 in stage 7.0 (TID 294). 1800 bytes result sent to driver
95319 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 7.0 (TID 296, localhost, PROCESS_LOCAL, 1970 bytes)
95319 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 14.0 in stage 7.0 (TID 296)
95323 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 7.0 (TID 294) in 1066 ms on localhost (13/83)
95327 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
95359 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
95359 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
95364 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
95364 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
95589 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000013_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000013
95594 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 13.0 in stage 7.0 (TID 295). 1800 bytes result sent to driver
95598 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 7.0 (TID 297, localhost, PROCESS_LOCAL, 1970 bytes)
95598 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 15.0 in stage 7.0 (TID 297)
95603 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 7.0 (TID 295) in 1062 ms on localhost (14/83)
95680 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
95680 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
95683 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
95683 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
96502 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
96839 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000014_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000014
96843 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 14.0 in stage 7.0 (TID 296). 1800 bytes result sent to driver
96844 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 7.0 (TID 298, localhost, PROCESS_LOCAL, 1970 bytes)
96844 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 16.0 in stage 7.0 (TID 298)
96848 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 7.0 (TID 296) in 1526 ms on localhost (15/83)
96890 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
96909 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
96909 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
96916 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
96916 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
97239 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000015_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000015
97243 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 15.0 in stage 7.0 (TID 297). 1800 bytes result sent to driver
97244 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 7.0 (TID 299, localhost, PROCESS_LOCAL, 1970 bytes)
97244 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 17.0 in stage 7.0 (TID 299)
97248 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 7.0 (TID 297) in 1647 ms on localhost (16/83)
97339 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
97339 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
97342 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
97342 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
98096 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
98396 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000016_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000016
98400 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 16.0 in stage 7.0 (TID 298). 1800 bytes result sent to driver
98402 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 7.0 (TID 300, localhost, PROCESS_LOCAL, 1970 bytes)
98402 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 18.0 in stage 7.0 (TID 300)
98405 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 7.0 (TID 298) in 1559 ms on localhost (17/83)
98468 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
98486 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
98486 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
98509 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
98509 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
98730 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000017_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000017
98734 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 17.0 in stage 7.0 (TID 299). 1800 bytes result sent to driver
98735 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 7.0 (TID 301, localhost, PROCESS_LOCAL, 1970 bytes)
98735 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 19.0 in stage 7.0 (TID 301)
98739 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 7.0 (TID 299) in 1491 ms on localhost (18/83)
98783 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
98784 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
98787 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
98787 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
99852 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
99964 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
100087 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000018_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000018
100092 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 18.0 in stage 7.0 (TID 300). 1800 bytes result sent to driver
100093 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 7.0 (TID 302, localhost, PROCESS_LOCAL, 1970 bytes)
100093 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 20.0 in stage 7.0 (TID 302)
100097 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 7.0 (TID 300) in 1692 ms on localhost (19/83)
100146 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
100146 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
100154 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
100154 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
100179 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000019_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000019
100184 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 19.0 in stage 7.0 (TID 301). 1800 bytes result sent to driver
100185 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 7.0 (TID 303, localhost, PROCESS_LOCAL, 1970 bytes)
100185 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 21.0 in stage 7.0 (TID 303)
100190 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 7.0 (TID 301) in 1451 ms on localhost (20/83)
100267 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
100267 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
100273 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
100273 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
101078 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
101095 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
101279 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000020_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000020
101284 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 20.0 in stage 7.0 (TID 302). 1800 bytes result sent to driver
101285 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 7.0 (TID 304, localhost, PROCESS_LOCAL, 1970 bytes)
101285 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 22.0 in stage 7.0 (TID 304)
101289 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 7.0 (TID 302) in 1193 ms on localhost (21/83)
101335 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
101335 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
101343 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
101343 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
101354 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000021_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000021
101359 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 21.0 in stage 7.0 (TID 303). 1800 bytes result sent to driver
101360 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 7.0 (TID 305, localhost, PROCESS_LOCAL, 1970 bytes)
101360 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 23.0 in stage 7.0 (TID 305)
101364 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 7.0 (TID 303) in 1176 ms on localhost (22/83)
101397 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
101397 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
101400 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
101400 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
102110 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
102118 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
102395 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000023_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000023
102399 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 23.0 in stage 7.0 (TID 305). 1800 bytes result sent to driver
102400 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 7.0 (TID 306, localhost, PROCESS_LOCAL, 1970 bytes)
102400 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 24.0 in stage 7.0 (TID 306)
102404 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 7.0 (TID 305) in 1042 ms on localhost (23/83)
102445 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000022_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000022
102449 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 22.0 in stage 7.0 (TID 304). 1800 bytes result sent to driver
102450 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 7.0 (TID 307, localhost, PROCESS_LOCAL, 1970 bytes)
102450 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 25.0 in stage 7.0 (TID 307)
102454 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 7.0 (TID 304) in 1165 ms on localhost (24/83)
102491 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
102491 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
102497 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
102497 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
102518 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
102518 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
102521 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
102521 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
103367 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
103369 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
103561 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000025_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000025
103566 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 25.0 in stage 7.0 (TID 307). 1800 bytes result sent to driver
103567 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 7.0 (TID 308, localhost, PROCESS_LOCAL, 1970 bytes)
103571 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 7.0 (TID 307) in 1118 ms on localhost (25/83)
103572 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 26.0 in stage 7.0 (TID 308)
103594 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000024_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000024
103598 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 24.0 in stage 7.0 (TID 306). 1800 bytes result sent to driver
103599 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 7.0 (TID 309, localhost, PROCESS_LOCAL, 1970 bytes)
103599 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 27.0 in stage 7.0 (TID 309)
103603 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 7.0 (TID 306) in 1200 ms on localhost (26/83)
103619 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
103619 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
103627 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
103627 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
103648 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
103648 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
103652 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
103652 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
104248 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
104276 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
104436 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000026_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000026
104440 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 26.0 in stage 7.0 (TID 308). 1800 bytes result sent to driver
104441 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 7.0 (TID 310, localhost, PROCESS_LOCAL, 1970 bytes)
104445 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 7.0 (TID 308) in 875 ms on localhost (27/83)
104445 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 28.0 in stage 7.0 (TID 310)
104469 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000027_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000027
104473 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 27.0 in stage 7.0 (TID 309). 1800 bytes result sent to driver
104475 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 7.0 (TID 311, localhost, PROCESS_LOCAL, 1970 bytes)
104475 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 29.0 in stage 7.0 (TID 311)
104478 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 7.0 (TID 309) in 876 ms on localhost (28/83)
104482 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
104482 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
104486 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
104486 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
104507 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
104507 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
104510 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
104510 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
105133 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
105232 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
105318 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000028_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000028
105323 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 28.0 in stage 7.0 (TID 310). 1800 bytes result sent to driver
105324 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 7.0 (TID 312, localhost, PROCESS_LOCAL, 1970 bytes)
105324 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 30.0 in stage 7.0 (TID 312)
105328 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 7.0 (TID 310) in 884 ms on localhost (29/83)
105373 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
105373 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
105381 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
105381 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
105418 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000029_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000029
105423 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 29.0 in stage 7.0 (TID 311). 1800 bytes result sent to driver
105424 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 7.0 (TID 313, localhost, PROCESS_LOCAL, 1970 bytes)
105424 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 31.0 in stage 7.0 (TID 313)
105428 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 7.0 (TID 311) in 950 ms on localhost (30/83)
105485 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
105485 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
105498 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
105498 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
106174 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
106274 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
106593 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000030_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000030
106597 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 30.0 in stage 7.0 (TID 312). 1800 bytes result sent to driver
106598 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 7.0 (TID 314, localhost, PROCESS_LOCAL, 1970 bytes)
106599 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 32.0 in stage 7.0 (TID 314)
106603 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 7.0 (TID 312) in 1276 ms on localhost (31/83)
106629 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000031_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000031
106634 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 31.0 in stage 7.0 (TID 313). 1800 bytes result sent to driver
106635 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 7.0 (TID 315, localhost, PROCESS_LOCAL, 1970 bytes)
106635 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 33.0 in stage 7.0 (TID 315)
106639 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 7.0 (TID 313) in 1212 ms on localhost (32/83)
106662 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
106662 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
106669 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
106669 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
106675 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
106675 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
106678 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
106678 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
107430 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
107447 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
107609 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000033_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000033
107614 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 33.0 in stage 7.0 (TID 315). 1800 bytes result sent to driver
107615 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 7.0 (TID 316, localhost, PROCESS_LOCAL, 1970 bytes)
107615 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 34.0 in stage 7.0 (TID 316)
107619 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 7.0 (TID 315) in 982 ms on localhost (33/83)
107726 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000032_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000032
107727 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
107727 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
107730 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 32.0 in stage 7.0 (TID 314). 1800 bytes result sent to driver
107731 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 7.0 (TID 317, localhost, PROCESS_LOCAL, 1970 bytes)
107734 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
107734 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
107735 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 35.0 in stage 7.0 (TID 317)
107735 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 7.0 (TID 314) in 1133 ms on localhost (34/83)
107772 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
107772 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
107775 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
107775 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
108326 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
108328 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
108492 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000034_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000034
108496 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 34.0 in stage 7.0 (TID 316). 1800 bytes result sent to driver
108497 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 7.0 (TID 318, localhost, PROCESS_LOCAL, 1970 bytes)
108497 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 36.0 in stage 7.0 (TID 318)
108501 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 7.0 (TID 316) in 883 ms on localhost (35/83)
108509 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000035_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000035
108513 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 35.0 in stage 7.0 (TID 317). 1800 bytes result sent to driver
108514 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 7.0 (TID 319, localhost, PROCESS_LOCAL, 1970 bytes)
108514 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 37.0 in stage 7.0 (TID 319)
108518 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 7.0 (TID 317) in 785 ms on localhost (36/83)
108533 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
108534 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
108540 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
108540 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
108541 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
108541 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
108543 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
108543 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109014 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
109077 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
109158 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000037_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000037
109162 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 37.0 in stage 7.0 (TID 319). 1800 bytes result sent to driver
109164 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 7.0 (TID 320, localhost, PROCESS_LOCAL, 1970 bytes)
109164 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 38.0 in stage 7.0 (TID 320)
109167 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 7.0 (TID 319) in 651 ms on localhost (37/83)
109202 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
109202 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109206 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
109207 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
109225 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000036_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000036
109229 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 36.0 in stage 7.0 (TID 318). 1800 bytes result sent to driver
109230 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 7.0 (TID 321, localhost, PROCESS_LOCAL, 1970 bytes)
109230 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 39.0 in stage 7.0 (TID 321)
109233 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 7.0 (TID 318) in 734 ms on localhost (38/83)
109254 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
109254 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109256 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
109256 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
109641 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
109692 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
109791 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000039_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000039
109796 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 39.0 in stage 7.0 (TID 321). 1800 bytes result sent to driver
109797 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 7.0 (TID 322, localhost, PROCESS_LOCAL, 1970 bytes)
109797 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 40.0 in stage 7.0 (TID 322)
109800 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 7.0 (TID 321) in 567 ms on localhost (39/83)
109821 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
109821 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109826 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
109826 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109833 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000038_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000038
109837 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 38.0 in stage 7.0 (TID 320). 1800 bytes result sent to driver
109838 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 7.0 (TID 323, localhost, PROCESS_LOCAL, 1970 bytes)
109838 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 41.0 in stage 7.0 (TID 323)
109841 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 7.0 (TID 320) in 675 ms on localhost (40/83)
109870 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
109870 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
109873 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
109873 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
110295 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
110338 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
110500 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000040_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000040
110502 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 40.0 in stage 7.0 (TID 322). 1800 bytes result sent to driver
110504 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 7.0 (TID 324, localhost, PROCESS_LOCAL, 1970 bytes)
110504 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 42.0 in stage 7.0 (TID 324)
110506 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 7.0 (TID 322) in 708 ms on localhost (41/83)
110531 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
110532 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
110538 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
110538 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
110566 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000041_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000041
110570 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 41.0 in stage 7.0 (TID 323). 1800 bytes result sent to driver
110571 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 7.0 (TID 325, localhost, PROCESS_LOCAL, 1970 bytes)
110571 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 43.0 in stage 7.0 (TID 325)
110574 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 7.0 (TID 323) in 734 ms on localhost (42/83)
110605 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
110605 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
110607 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
110607 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
110969 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
111023 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
111091 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000042_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000042
111093 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 42.0 in stage 7.0 (TID 324). 1800 bytes result sent to driver
111095 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 7.0 (TID 326, localhost, PROCESS_LOCAL, 1970 bytes)
111095 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 44.0 in stage 7.0 (TID 326)
111098 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 7.0 (TID 324) in 592 ms on localhost (43/83)
111122 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
111122 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111126 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
111127 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
111191 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000043_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000043
111194 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 43.0 in stage 7.0 (TID 325). 1800 bytes result sent to driver
111195 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 7.0 (TID 327, localhost, PROCESS_LOCAL, 1970 bytes)
111195 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 45.0 in stage 7.0 (TID 327)
111197 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 7.0 (TID 325) in 625 ms on localhost (44/83)
111218 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
111218 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111220 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
111220 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111498 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
111590 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
111632 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000044_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000044
111637 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 44.0 in stage 7.0 (TID 326). 1800 bytes result sent to driver
111637 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 7.0 (TID 328, localhost, PROCESS_LOCAL, 1970 bytes)
111638 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 46.0 in stage 7.0 (TID 328)
111639 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 7.0 (TID 326) in 543 ms on localhost (45/83)
111664 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
111664 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111670 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
111670 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111724 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000045_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000045
111726 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 45.0 in stage 7.0 (TID 327). 1800 bytes result sent to driver
111727 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 7.0 (TID 329, localhost, PROCESS_LOCAL, 1970 bytes)
111728 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 47.0 in stage 7.0 (TID 329)
111730 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 7.0 (TID 327) in 534 ms on localhost (46/83)
111750 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
111750 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
111752 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
111752 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
112052 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
112112 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
112207 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000046_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000046
112210 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 46.0 in stage 7.0 (TID 328). 1800 bytes result sent to driver
112210 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 7.0 (TID 330, localhost, PROCESS_LOCAL, 1970 bytes)
112211 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 48.0 in stage 7.0 (TID 330)
112212 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 7.0 (TID 328) in 574 ms on localhost (47/83)
112232 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
112232 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
112236 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
112236 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
112240 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000047_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000047
112243 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 47.0 in stage 7.0 (TID 329). 1800 bytes result sent to driver
112244 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 7.0 (TID 331, localhost, PROCESS_LOCAL, 1970 bytes)
112244 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 49.0 in stage 7.0 (TID 331)
112246 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 7.0 (TID 329) in 517 ms on localhost (48/83)
112264 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
112264 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
112266 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
112266 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
112757 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
112811 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
112907 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000048_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000048
112910 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 48.0 in stage 7.0 (TID 330). 1800 bytes result sent to driver
112911 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 7.0 (TID 332, localhost, PROCESS_LOCAL, 1970 bytes)
112911 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 50.0 in stage 7.0 (TID 332)
112926 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 7.0 (TID 330) in 701 ms on localhost (49/83)
112958 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
112958 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
112962 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
112963 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
112999 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000049_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000049
113003 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 49.0 in stage 7.0 (TID 331). 1800 bytes result sent to driver
113004 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 7.0 (TID 333, localhost, PROCESS_LOCAL, 1970 bytes)
113004 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 51.0 in stage 7.0 (TID 333)
113008 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 7.0 (TID 331) in 761 ms on localhost (50/83)
113033 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
113033 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
113035 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
113035 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
113616 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
113669 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
113824 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000050_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000050
113828 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 50.0 in stage 7.0 (TID 332). 1800 bytes result sent to driver
113830 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 7.0 (TID 334, localhost, PROCESS_LOCAL, 1970 bytes)
113834 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 7.0 (TID 332) in 920 ms on localhost (51/83)
113834 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 52.0 in stage 7.0 (TID 334)
113883 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
113883 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
113891 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
113891 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
113898 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000051_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000051
113903 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 51.0 in stage 7.0 (TID 333). 1800 bytes result sent to driver
113904 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 7.0 (TID 335, localhost, PROCESS_LOCAL, 1970 bytes)
113904 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 53.0 in stage 7.0 (TID 335)
113909 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 7.0 (TID 333) in 902 ms on localhost (52/83)
113947 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
113947 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
113950 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
113950 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
114660 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
114712 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
114940 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000053_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000053
114945 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 53.0 in stage 7.0 (TID 335). 1800 bytes result sent to driver
114946 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 7.0 (TID 336, localhost, PROCESS_LOCAL, 1970 bytes)
114947 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 54.0 in stage 7.0 (TID 336)
114950 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 7.0 (TID 335) in 1043 ms on localhost (53/83)
114950 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000052_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000052
114954 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 52.0 in stage 7.0 (TID 334). 1800 bytes result sent to driver
114956 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 7.0 (TID 337, localhost, PROCESS_LOCAL, 1970 bytes)
114956 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 55.0 in stage 7.0 (TID 337)
114959 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 7.0 (TID 334) in 1127 ms on localhost (54/83)
114977 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
114977 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
115000 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
115000 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
115011 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
115011 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
115018 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
115018 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
115839 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
115859 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
116107 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000055_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000055
116111 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 55.0 in stage 7.0 (TID 337). 1800 bytes result sent to driver
116112 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 7.0 (TID 338, localhost, PROCESS_LOCAL, 1970 bytes)
116113 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 56.0 in stage 7.0 (TID 338)
116116 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 7.0 (TID 337) in 1158 ms on localhost (55/83)
116146 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
116147 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
116152 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
116152 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
116181 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000054_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000054
116184 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 54.0 in stage 7.0 (TID 336). 1800 bytes result sent to driver
116185 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 7.0 (TID 339, localhost, PROCESS_LOCAL, 1970 bytes)
116186 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 57.0 in stage 7.0 (TID 339)
116188 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 7.0 (TID 336) in 1240 ms on localhost (56/83)
116220 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
116220 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
116223 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
116223 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
116600 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
116652 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
116805 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000056_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000056
116809 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 56.0 in stage 7.0 (TID 338). 1800 bytes result sent to driver
116810 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 7.0 (TID 340, localhost, PROCESS_LOCAL, 1970 bytes)
116810 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Running task 58.0 in stage 7.0 (TID 340)
116814 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 7.0 (TID 338) in 699 ms on localhost (57/83)
116838 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
116838 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
116844 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
116844 [Executor task launch worker-0] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
116872 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000057_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000057
116876 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 57.0 in stage 7.0 (TID 339). 1800 bytes result sent to driver
116877 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 7.0 (TID 341, localhost, PROCESS_LOCAL, 1970 bytes)
116877 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 59.0 in stage 7.0 (TID 341)
116881 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 7.0 (TID 339) in 692 ms on localhost (58/83)
116936 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
116936 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
116939 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
116939 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
117439 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
117493 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
117638 [Executor task launch worker-0] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000058_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000058
117643 [Executor task launch worker-0] INFO org.apache.spark.executor.Executor - Finished task 58.0 in stage 7.0 (TID 340). 1800 bytes result sent to driver
117644 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 7.0 (TID 342, localhost, PROCESS_LOCAL, 1970 bytes)
117644 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 60.0 in stage 7.0 (TID 342)
117647 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 7.0 (TID 340) in 835 ms on localhost (59/83)
117663 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000059_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000059
117668 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 59.0 in stage 7.0 (TID 341). 1800 bytes result sent to driver
117669 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 7.0 (TID 343, localhost, PROCESS_LOCAL, 1970 bytes)
117669 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 61.0 in stage 7.0 (TID 343)
117672 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 7.0 (TID 341) in 792 ms on localhost (60/83)
117686 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
117686 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
117694 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
117694 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
117695 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
117695 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
117698 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
117698 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
118268 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
118302 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
118472 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000061_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000061
118476 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 61.0 in stage 7.0 (TID 343). 1800 bytes result sent to driver
118477 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 7.0 (TID 344, localhost, PROCESS_LOCAL, 1970 bytes)
118477 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 62.0 in stage 7.0 (TID 344)
118481 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 7.0 (TID 343) in 809 ms on localhost (61/83)
118488 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000060_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000060
118493 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 60.0 in stage 7.0 (TID 342). 1800 bytes result sent to driver
118494 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 7.0 (TID 345, localhost, PROCESS_LOCAL, 1970 bytes)
118498 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 7.0 (TID 342) in 851 ms on localhost (62/83)
118502 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 63.0 in stage 7.0 (TID 345)
118510 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
118510 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
118516 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
118516 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
118541 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
118542 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
118544 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
118544 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
119288 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
119306 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
119481 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000063_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000063
119485 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 63.0 in stage 7.0 (TID 345). 1800 bytes result sent to driver
119486 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 7.0 (TID 346, localhost, PROCESS_LOCAL, 1970 bytes)
119487 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 64.0 in stage 7.0 (TID 346)
119490 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 7.0 (TID 345) in 993 ms on localhost (63/83)
119507 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000062_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000062
119511 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 62.0 in stage 7.0 (TID 344). 1800 bytes result sent to driver
119512 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 7.0 (TID 347, localhost, PROCESS_LOCAL, 1970 bytes)
119514 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 65.0 in stage 7.0 (TID 347)
119516 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 7.0 (TID 344) in 1037 ms on localhost (64/83)
119526 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
119526 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
119532 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
119533 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
119564 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
119564 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
119567 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
119567 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
120117 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
120149 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
120247 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000064_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000064
120249 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 64.0 in stage 7.0 (TID 346). 1800 bytes result sent to driver
120251 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 7.0 (TID 348, localhost, PROCESS_LOCAL, 1970 bytes)
120251 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 66.0 in stage 7.0 (TID 348)
120253 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 7.0 (TID 346) in 766 ms on localhost (65/83)
120272 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000065_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000065
120274 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
120274 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
120276 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 65.0 in stage 7.0 (TID 347). 1800 bytes result sent to driver
120277 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 7.0 (TID 349, localhost, PROCESS_LOCAL, 1970 bytes)
120277 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 67.0 in stage 7.0 (TID 349)
120279 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
120279 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
120281 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 7.0 (TID 347) in 765 ms on localhost (66/83)
120302 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
120302 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
120303 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
120304 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
120618 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
120632 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
120963 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000066_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000066
120966 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 66.0 in stage 7.0 (TID 348). 1800 bytes result sent to driver
120967 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 7.0 (TID 350, localhost, PROCESS_LOCAL, 1970 bytes)
120967 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 68.0 in stage 7.0 (TID 350)
120969 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 7.0 (TID 348) in 717 ms on localhost (67/83)
120990 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
120991 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
120995 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
120995 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
121005 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000067_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000067
121007 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 67.0 in stage 7.0 (TID 349). 1800 bytes result sent to driver
121008 [sparkDriver-akka.actor.default-dispatcher-13] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 7.0 (TID 351, localhost, PROCESS_LOCAL, 1970 bytes)
121009 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 69.0 in stage 7.0 (TID 351)
121011 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 7.0 (TID 349) in 733 ms on localhost (68/83)
121041 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
121042 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
121045 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
121045 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
121463 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
121471 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
121605 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000068_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000068
121607 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 68.0 in stage 7.0 (TID 350). 1800 bytes result sent to driver
121608 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 7.0 (TID 352, localhost, PROCESS_LOCAL, 1970 bytes)
121608 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 70.0 in stage 7.0 (TID 352)
121612 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 7.0 (TID 350) in 642 ms on localhost (69/83)
121613 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000069_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000069
121616 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 69.0 in stage 7.0 (TID 351). 1800 bytes result sent to driver
121616 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 7.0 (TID 353, localhost, PROCESS_LOCAL, 1970 bytes)
121617 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 71.0 in stage 7.0 (TID 353)
121620 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 7.0 (TID 351) in 608 ms on localhost (70/83)
121636 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
121636 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
121638 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
121638 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
121640 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
121640 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
121640 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
121640 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122063 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
122099 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
122196 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000070_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000070
122200 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 70.0 in stage 7.0 (TID 352). 1800 bytes result sent to driver
122201 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 7.0 (TID 354, localhost, PROCESS_LOCAL, 1970 bytes)
122202 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 72.0 in stage 7.0 (TID 354)
122205 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 7.0 (TID 352) in 594 ms on localhost (71/83)
122226 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
122226 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122229 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000071_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000071
122230 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
122230 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122233 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 71.0 in stage 7.0 (TID 353). 1800 bytes result sent to driver
122234 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 7.0 (TID 355, localhost, PROCESS_LOCAL, 1970 bytes)
122234 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 73.0 in stage 7.0 (TID 355)
122238 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 7.0 (TID 353) in 618 ms on localhost (72/83)
122256 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
122256 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122258 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
122258 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122570 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
122589 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
122754 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000072_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000072
122758 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 72.0 in stage 7.0 (TID 354). 1800 bytes result sent to driver
122760 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 7.0 (TID 356, localhost, PROCESS_LOCAL, 1970 bytes)
122760 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 74.0 in stage 7.0 (TID 356)
122762 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 7.0 (TID 354) in 559 ms on localhost (73/83)
122771 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000073_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000073
122775 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 73.0 in stage 7.0 (TID 355). 1800 bytes result sent to driver
122776 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 7.0 (TID 357, localhost, PROCESS_LOCAL, 1970 bytes)
122776 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 75.0 in stage 7.0 (TID 357)
122778 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 7.0 (TID 355) in 542 ms on localhost (74/83)
122781 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
122781 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
122785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122798 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
122798 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
122799 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
122799 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
123116 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
123121 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
123237 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000074_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000074
123240 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 74.0 in stage 7.0 (TID 356). 1800 bytes result sent to driver
123241 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 7.0 (TID 358, localhost, PROCESS_LOCAL, 1970 bytes)
123241 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 76.0 in stage 7.0 (TID 358)
123243 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 7.0 (TID 356) in 482 ms on localhost (75/83)
123262 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000075_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000075
123263 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
123263 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
123265 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 75.0 in stage 7.0 (TID 357). 1800 bytes result sent to driver
123266 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 7.0 (TID 359, localhost, PROCESS_LOCAL, 1970 bytes)
123266 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 77.0 in stage 7.0 (TID 359)
123267 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
123267 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
123269 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 7.0 (TID 357) in 491 ms on localhost (76/83)
123286 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
123286 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
123288 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
123288 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
123581 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
123618 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
123704 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000076_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000076
123706 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 76.0 in stage 7.0 (TID 358). 1800 bytes result sent to driver
123707 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 7.0 (TID 360, localhost, PROCESS_LOCAL, 1970 bytes)
123707 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 78.0 in stage 7.0 (TID 360)
123710 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 7.0 (TID 358) in 467 ms on localhost (77/83)
123729 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
123729 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
123733 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
123733 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
123745 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000077_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000077
123748 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 77.0 in stage 7.0 (TID 359). 1800 bytes result sent to driver
123749 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 7.0 (TID 361, localhost, PROCESS_LOCAL, 1970 bytes)
123752 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 7.0 (TID 359) in 484 ms on localhost (78/83)
123752 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 79.0 in stage 7.0 (TID 361)
123774 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
123774 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
123776 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
123776 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124067 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
124106 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
124179 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000078_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000078
124181 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 78.0 in stage 7.0 (TID 360). 1800 bytes result sent to driver
124182 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 7.0 (TID 362, localhost, PROCESS_LOCAL, 1970 bytes)
124183 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 80.0 in stage 7.0 (TID 362)
124184 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 7.0 (TID 360) in 475 ms on localhost (79/83)
124205 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
124205 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124209 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
124209 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124220 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000079_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000079
124225 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 79.0 in stage 7.0 (TID 361). 1800 bytes result sent to driver
124226 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 7.0 (TID 363, localhost, PROCESS_LOCAL, 1970 bytes)
124226 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Running task 81.0 in stage 7.0 (TID 363)
124229 [task-result-getter-1] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 7.0 (TID 361) in 477 ms on localhost (80/83)
124260 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
124260 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124261 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
124261 [Executor task launch worker-1] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124600 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
124718 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
124737 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000080_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000080
124741 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 80.0 in stage 7.0 (TID 362). 1800 bytes result sent to driver
124742 [sparkDriver-akka.actor.default-dispatcher-5] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 7.0 (TID 364, localhost, PROCESS_LOCAL, 1970 bytes)
124742 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Running task 82.0 in stage 7.0 (TID 364)
124749 [task-result-getter-2] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 7.0 (TID 362) in 561 ms on localhost (81/83)
124777 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 83 non-empty blocks out of 83 blocks
124777 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 36 non-empty blocks out of 58 blocks
124785 [Executor task launch worker-2] INFO org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
124878 [Executor task launch worker-1] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000081_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000081
124881 [Executor task launch worker-1] INFO org.apache.spark.executor.Executor - Finished task 81.0 in stage 7.0 (TID 363). 1800 bytes result sent to driver
124883 [task-result-getter-3] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 7.0 (TID 363) in 657 ms on localhost (82/83)
125340 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
125503 [Executor task launch worker-2] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201506121510_0096_r_000082_0' to hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16/_temporary/0/task_201506121510_0096_r_000082
125507 [Executor task launch worker-2] INFO org.apache.spark.executor.Executor - Finished task 82.0 in stage 7.0 (TID 364). 1800 bytes result sent to driver
125512 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 7.0 (TID 364) in 766 ms on localhost (83/83)
125512 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Stage 7 (saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156) finished in 39.245 s
125512 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool
125513 [main] INFO org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsNewAPIHadoopDataset at ViewThroughCorrelation.scala:156, took 39.341451 s
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
127225 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
127226 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
127227 [main] INFO org.spark-project.jetty.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
127281 [main] INFO org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://vtqaana-cloudera01.dealer.ddc:4041
127284 [main] INFO org.apache.spark.scheduler.DAGScheduler - Stopping DAGScheduler
127343 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.MapOutputTrackerMasterActor - MapOutputTrackerActor stopped!
127529 [main] INFO org.apache.spark.storage.MemoryStore - MemoryStore cleared
127529 [main] INFO org.apache.spark.storage.BlockManager - BlockManager stopped
127531 [main] INFO org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
127535 [sparkDriver-akka.actor.default-dispatcher-14] INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorActor - OutputCommitCoordinator stopped!
127546 [sparkDriver-akka.actor.default-dispatcher-5] INFO akka.remote.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
127549 [sparkDriver-akka.actor.default-dispatcher-5] INFO akka.remote.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
127718 [main] INFO org.apache.spark.SparkContext - Successfully stopped SparkContext
127735 [sparkDriver-akka.actor.default-dispatcher-13] INFO Remoting - Remoting shut down
127736 [sparkDriver-akka.actor.default-dispatcher-14] INFO akka.remote.RemoteActorRefProvider$RemotingTerminator - Remoting shut down.
127811 [main] INFO org.apache.hadoop.mapred.Task - Task:attempt_1433901314076_29226_m_000000_0 is done. And is in the process of committing
127975 [main] INFO org.apache.hadoop.mapred.Task - Task attempt_1433901314076_29226_m_000000_0 is allowed to commit now
127999 [main] INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_1433901314076_29226_m_000000_0' to hdfs://nameservice1/user/rtb-system/oozie-oozi/0007520-150605023713992-oozie-oozi-W/RtbSparkDeploy--spark/output/_temporary/1/task_1433901314076_29226_m_000000
128174 [main] INFO org.apache.hadoop.mapred.Task - Task 'attempt_1433901314076_29226_m_000000_0' done.
128175 [main] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping MapTask metrics system...
128176 [main] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - MapTask metrics system stopped.
128177 [main] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - MapTask metrics system shutdown complete.

--------------------------------------------------------------------------------------------------------------------

Heart beat
Starting the execution of prepare actions
Completed the execution of prepare actions successfully

Files in current dir:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/.
======================
File: unused-1.0.0.jar
File: default_container_executor_session.sh
File: oozie-sharelib-oozie-4.1.0-cdh5.4.1.jar
File: .default_container_executor.sh.crc
File: .default_container_executor_session.sh.crc
File: oozie-hadoop-utils-2.6.0-cdh5.4.1.oozie-4.1.0-cdh5.4.1.jar
File: spark-assembly.jar
File: .job.xml.crc
File: commons-lang-2.4.jar
File: .action.xml.crc
File: .launch_container.sh.crc
File: job.xml
File: guava-14.0.1.jar
File: oozie-sharelib-spark-4.1.0-cdh5.4.1.jar
File: json-simple-1.1.jar
File: rtb-oozie-spark-deploy-1.0.2.jar
File: container_tokens
File: .container_tokens.crc
File: launch_container.sh
File: default_container_executor.sh
Dir: tmp
File: action.xml

Oozie Java/Map-Reduce/Pig action launcher-job configuration
=================================================================
Workflow job id   : 0007520-150605023713992-oozie-oozi-W
Workflow action id: 0007520-150605023713992-oozie-oozi-W@RtbSparkDeploy

Classpath         :
------------------------
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002
  job.jar/job.jar
  job.jar/classes/
  job.jar/lib/*
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/unused-1.0.0.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-sharelib-oozie-4.1.0-cdh5.4.1.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-hadoop-utils-2.6.0-cdh5.4.1.oozie-4.1.0-cdh5.4.1.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/spark-assembly.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/commons-lang-2.4.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/guava-14.0.1.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-sharelib-spark-4.1.0-cdh5.4.1.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/json-simple-1.1.jar
  /data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/rtb-oozie-spark-deploy-1.0.2.jar
  /etc/hadoop/conf.cloudera.yarn
  /var/run/cloudera-scm-agent/process/6403-yarn-NODEMANAGER
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-jackson.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-aws-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-annotations.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-nfs.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-thrift.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-common.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-protobuf.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-auth-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format-sources.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-avro.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-auth.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-tools.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-annotations-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-scala_2.10.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-pig-bundle.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-pig.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-encoding.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-column.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-aws.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-scrooge_2.10.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-hadoop-bundle.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-test-hadoop2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-nfs-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-generator.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-cascading.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format-javadoc.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-2.6.0-cdh5.4.1-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-hadoop.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-server-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jasper-compiler-5.5.23.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/junit-4.11.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/paranamer-2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/slf4j-log4j12.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-framework-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-json-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/guava-11.0.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-logging-1.1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/aws-java-sdk-1.7.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-compress-1.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-el-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/asm-3.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jettison-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/mockito-all-1.8.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/avro.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/xmlenc-0.52.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/snappy-java-1.0.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsr305-3.0.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/log4j-1.2.17.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/hue-plugins-3.7.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/protobuf-java-2.5.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-io-2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/xz-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/stax-api-1.0-2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-core-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jets3t-0.9.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/httpcore-4.2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-codec-1.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/activation-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-recipes-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-net-3.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-xc-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/java-xmlbuilder-0.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/slf4j-api-1.7.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/netty-3.6.2.Final.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-client-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-cli-1.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/logredactor-1.0.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/zookeeper.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-math3-3.1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/gson-2.2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-collections-3.2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-httpclient-3.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/httpclient-4.2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsch-0.1.42.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/hamcrest-core-1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jaxb-api-2.2.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jasper-runtime-5.5.23.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-lang-2.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-core-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsp-api-2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-beanutils-1.7.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/htrace-core-3.0.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-configuration-1.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-digester-1.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/api-util-1.0.0-M20.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/servlet-api-2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.4.1-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jersey-server-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/guava-11.0.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-el-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/asm-3.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/xmlenc-0.52.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/log4j-1.2.17.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-io-2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-codec-1.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-cli-1.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-lang-2.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jersey-core-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jsp-api-2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/htrace-core-3.0.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/servlet-api-2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-common-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-client-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-client.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-registry.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-tests-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-registry-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-api.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-common.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-api-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-common.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-common-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-server-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/javax.inject-1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/spark-1.3.0-cdh5.4.1-yarn-shuffle.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-json-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guava-11.0.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guice-servlet-3.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/aopalliance-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-client-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/asm-3.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jettison-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jsr305-3.0.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/log4j-1.2.17.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-guice-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jline-2.11.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-io-2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/xz-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/stax-api-1.0-2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-codec-1.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/activation-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-cli-1.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/zookeeper.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-collections-3.2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-lang-2.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-core-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guice-3.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/servlet-api-2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-server-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jasper-compiler-5.5.23.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-core-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/microsoft-windowsazure-storage-sdk-0.6.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/junit-4.11.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/paranamer-2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-streaming.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-extras.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-framework-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-json-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-jaxrs-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/guava-11.0.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-common-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-logging-1.1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-rumen-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-app-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/api-asn1-api-1.0.0-M20.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-sls.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-compress-1.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-extras-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-core-2.2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-el-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-mapper-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jetty-util-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/asm-3.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jettison-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/mockito-all-1.8.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-nativetask-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.1-tests.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/avro.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/xmlenc-0.52.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jetty-6.1.26.cloudera.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/apacheds-kerberos-codec-2.0.0-M15.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-auth-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/snappy-java-1.0.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsr305-3.0.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/log4j-1.2.17.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-auth.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-archives.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/protobuf-java-2.5.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-rumen.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-io-2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/apacheds-i18n-2.0.0-M15.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-azure.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-sls-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-azure-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/xz-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/stax-api-1.0-2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-beanutils-core-1.8.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-common.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-databind-2.2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-core-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jets3t-0.9.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/httpcore-4.2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-codec-1.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-gridmix.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/activation-1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-recipes-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-app.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-net-3.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-annotations-2.2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-xc-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/java-xmlbuilder-0.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-client-2.7.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-cli-1.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-datajoin-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-ant.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-datajoin.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/zookeeper.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/metrics-core-3.0.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-math3-3.1.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-core.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/gson-2.2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-collections-3.2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-archives-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-httpclient-3.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-gridmix-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/httpclient-4.2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsch-0.1.42.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jaxb-impl-2.2.3-1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hamcrest-core-1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-distcp-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jaxb-api-2.2.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jasper-runtime-5.5.23.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-lang-2.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-ant-2.6.0-cdh5.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-core-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsp-api-2.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-beanutils-1.7.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/htrace-core-3.0.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-nativetask.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-configuration-1.6.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-distcp.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-digester-1.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/api-util-1.0.0-M20.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/servlet-api-2.5.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/junit-4.11.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/paranamer-2.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/javax.inject-1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/asm-3.2.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/avro.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/commons-io-2.4.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/xz-1.0.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar
  /opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/guice-3.0.jar
------------------------

Main class        : org.apache.oozie.action.hadoop.SparkMain

Maximum output    : 2048

Arguments         :
                    -n
                    RTBViewThroughCorrelation
                    --kryoClasses
                    com.dealer.analytics.ad.intake.RTBEnrichedImpression,com.dealer.analytics.pixall.intake.PixAllHit,com.dealer.analytics.ad.intake.RTBImpression
                    --properties
                    mutableOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16,permOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16,viewsFile=hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16,summarizeTimeUnit=hour,mutableWindowStart=2015-05-12T16:00:00
                    --impressionFiles
                    hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16

Java System Properties:
------------------------
#
#Fri Jun 12 15:09:10 UTC 2015
java.runtime.name=Java(TM) SE Runtime Environment
sun.boot.library.path=/usr/java/jdk1.7.0_67-cloudera/jre/lib/amd64
java.vm.version=24.65-b04
oozie.action.externalChildIDs=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/externalChildIDs
hadoop.root.logger=INFO,CLA
java.vm.vendor=Oracle Corporation
java.vendor.url=http\://java.oracle.com/
path.separator=\:
java.vm.name=Java HotSpot(TM) 64-Bit Server VM
file.encoding.pkg=sun.io
oozie.job.launch.time=1434121738219
user.country=US
sun.java.launcher=SUN_STANDARD
sun.os.patch.level=unknown
java.vm.specification.name=Java Virtual Machine Specification
user.dir=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002
oozie.action.newId=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/newId
java.runtime.version=1.7.0_67-b01
java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment
java.endorsed.dirs=/usr/java/jdk1.7.0_67-cloudera/jre/lib/endorsed
os.arch=amd64
oozie.job.id=0007520-150605023713992-oozie-oozi-W
oozie.action.id=0007520-150605023713992-oozie-oozi-W@RtbSparkDeploy
yarn.app.container.log.dir=/var/log/hadoop-yarn/container/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002
java.io.tmpdir=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/tmp
line.separator=\n
oozie.action.output.properties=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/output.properties
java.vm.specification.vendor=Oracle Corporation
os.name=Linux
log4j.configuration=container-log4j.properties
sun.jnu.encoding=UTF-8
java.library.path=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native\:\:/usr/java/packages/lib/amd64\:/usr/lib64\:/lib64\:/lib\:/usr/lib
oozie.action.conf.xml=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/action.xml
hadoop.metrics.log.level=WARN
java.specification.name=Java Platform API Specification
java.class.version=51.0
java.net.preferIPv4Stack=true
sun.management.compiler=HotSpot 64-Bit Tiered Compilers
os.version=2.6.32-279.11.1.el6.x86_64
oozie.action.error.properties=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/error.properties
yarn.app.container.log.filesize=0
user.home=/var/lib/hadoop-yarn
user.timezone=Universal
java.awt.printerjob=sun.print.PSPrinterJob
file.encoding=UTF-8
java.specification.version=1.7
java.class.path=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002\:job.jar/job.jar\:job.jar/classes/\:job.jar/lib/*\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/unused-1.0.0.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-sharelib-oozie-4.1.0-cdh5.4.1.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-hadoop-utils-2.6.0-cdh5.4.1.oozie-4.1.0-cdh5.4.1.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/spark-assembly.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/commons-lang-2.4.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/guava-14.0.1.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/oozie-sharelib-spark-4.1.0-cdh5.4.1.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/json-simple-1.1.jar\:/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/rtb-oozie-spark-deploy-1.0.2.jar\:/etc/hadoop/conf.cloudera.yarn\:/var/run/cloudera-scm-agent/process/6403-yarn-NODEMANAGER\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-jackson.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-aws-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-annotations.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-nfs.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-thrift.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-common.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-protobuf.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-auth-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format-sources.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-avro.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-auth.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-tools.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-annotations-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-scala_2.10.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-pig-bundle.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-pig.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-encoding.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-column.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-aws.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-scrooge_2.10.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-hadoop-bundle.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-test-hadoop2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-nfs-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-generator.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-cascading.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-format-javadoc.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/hadoop-common-2.6.0-cdh5.4.1-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/parquet-hadoop.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-server-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jasper-compiler-5.5.23.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/junit-4.11.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/paranamer-2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/slf4j-log4j12.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-framework-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-json-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/guava-11.0.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-logging-1.1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/aws-java-sdk-1.7.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-compress-1.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-el-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/asm-3.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jettison-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/mockito-all-1.8.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/avro.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/xmlenc-0.52.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/snappy-java-1.0.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsr305-3.0.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/log4j-1.2.17.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/hue-plugins-3.7.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/protobuf-java-2.5.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-io-2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/xz-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/stax-api-1.0-2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-core-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jets3t-0.9.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/httpcore-4.2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-codec-1.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/activation-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-recipes-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-net-3.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jackson-xc-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/java-xmlbuilder-0.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/slf4j-api-1.7.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/netty-3.6.2.Final.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/curator-client-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-cli-1.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/logredactor-1.0.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/zookeeper.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-math3-3.1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/gson-2.2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-collections-3.2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-httpclient-3.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/httpclient-4.2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsch-0.1.42.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/hamcrest-core-1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jaxb-api-2.2.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jasper-runtime-5.5.23.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-lang-2.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jersey-core-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/jsp-api-2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-beanutils-1.7.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/htrace-core-3.0.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-configuration-1.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/commons-digester-1.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/api-util-1.0.0-M20.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/servlet-api-2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/hadoop-hdfs-2.6.0-cdh5.4.1-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jersey-server-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/guava-11.0.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-el-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/asm-3.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/xmlenc-0.52.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/log4j-1.2.17.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-io-2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-codec-1.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-cli-1.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/commons-lang-2.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jersey-core-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/jsp-api-2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/htrace-core-3.0.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-hdfs/lib/servlet-api-2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-common-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-client-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-client.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-registry.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-tests-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-registry-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-api.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-common.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-api-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-common.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/hadoop-yarn-server-common-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-server-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/javax.inject-1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/spark-1.3.0-cdh5.4.1-yarn-shuffle.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-json-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guava-11.0.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guice-servlet-3.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/aopalliance-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-client-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/asm-3.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jettison-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jsr305-3.0.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/log4j-1.2.17.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-guice-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jline-2.11.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-io-2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/xz-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/stax-api-1.0-2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-codec-1.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/activation-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-cli-1.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/zookeeper.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-collections-3.2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/commons-lang-2.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/jersey-core-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/guice-3.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-yarn/lib/servlet-api-2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-server-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jasper-compiler-5.5.23.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-core-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/microsoft-windowsazure-storage-sdk-0.6.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/junit-4.11.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/paranamer-2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-streaming.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-extras.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-framework-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-json-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-jaxrs-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/guava-11.0.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-common-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-logging-1.1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-rumen-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-app-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/api-asn1-api-1.0.0-M20.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-sls.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-compress-1.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-extras-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-core-2.2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-el-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-mapper-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jetty-util-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/asm-3.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jettison-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/mockito-all-1.8.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-nativetask-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.1-tests.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/avro.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/xmlenc-0.52.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jetty-6.1.26.cloudera.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/apacheds-kerberos-codec-2.0.0-M15.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-auth-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/snappy-java-1.0.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsr305-3.0.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/log4j-1.2.17.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-auth.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-archives.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/protobuf-java-2.5.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-rumen.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-io-2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/apacheds-i18n-2.0.0-M15.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-azure.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-sls-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-azure-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/xz-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/stax-api-1.0-2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-beanutils-core-1.8.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-common.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-databind-2.2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-core-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jets3t-0.9.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/httpcore-4.2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-codec-1.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-gridmix.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/activation-1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-recipes-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-app.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-net-3.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-annotations-2.2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jackson-xc-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/java-xmlbuilder-0.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/curator-client-2.7.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-cli-1.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-datajoin-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-ant.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-datajoin.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/zookeeper.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/metrics-core-3.0.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-math3-3.1.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-core.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/gson-2.2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-collections-3.2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-archives-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-httpclient-3.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-gridmix-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/httpclient-4.2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsch-0.1.42.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jaxb-impl-2.2.3-1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hamcrest-core-1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-distcp-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jaxb-api-2.2.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jasper-runtime-5.5.23.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-lang-2.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-ant-2.6.0-cdh5.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jersey-core-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/jsp-api-2.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-beanutils-1.7.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/htrace-core-3.0.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-mapreduce-client-nativetask.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-configuration-1.6.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/hadoop-distcp.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/commons-digester-1.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/api-util-1.0.0-M20.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/servlet-api-2.5.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/junit-4.11.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/paranamer-2.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/javax.inject-1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/asm-3.2.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/avro.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/commons-io-2.4.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/xz-1.0.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar\:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop-mapreduce/lib/guice-3.0.jar\:
user.name=yarn
java.vm.specification.version=1.7
sun.java.command=org.apache.hadoop.mapred.YarnChild 10.12.12.24 45300 attempt_1433901314076_29226_m_000000_0 50577534877698
java.home=/usr/java/jdk1.7.0_67-cloudera/jre
sun.arch.data.model=64
user.language=en
java.specification.vendor=Oracle Corporation
awt.toolkit=sun.awt.X11.XToolkit
java.vm.info=mixed mode
java.version=1.7.0_67
java.ext.dirs=/usr/java/jdk1.7.0_67-cloudera/jre/lib/ext\:/usr/java/packages/lib/ext
sun.boot.class.path=/usr/java/jdk1.7.0_67-cloudera/jre/lib/resources.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/rt.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/sunrsasign.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/jsse.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/jce.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/charsets.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/lib/jfr.jar\:/usr/java/jdk1.7.0_67-cloudera/jre/classes
java.vendor=Oracle Corporation
file.separator=/
oozie.launcher.job.id=job_1433901314076_29226
oozie.action.stats.properties=/data/8/yarn/nm/usercache/rtb-system/appcache/application_1433901314076_29226/container_e46_1433901314076_29226_01_000002/stats.properties
java.vendor.url.bug=http\://bugreport.sun.com/bugreport/
sun.io.unicode.encoding=UnicodeLittle
sun.cpu.endian=little
sun.cpu.isalist=
------------------------

=================================================================

>>> Invoking Main class now >>>

Spark Action Main class        : org.apache.spark.deploy.SparkSubmit

Oozie Spark action configuration
=================================================================

                    --master
                    yarn-client
                    --deploy-mode
                    client
                    --name
                    ViewThroughCorrelationJob
                    --class
                    com.dealertrack.advertising.rtb.job.ViewBatchJob
                    --conf
                    spark.driver.extraLibraryPath=/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
                    --conf
                    spark.serializer=org.apache.spark.serializer.KryoSerializer
                    --conf
                    spark.eventLog.enabled=true
                    --conf
                    spark.eventLog.dir=hdfs://nameservice1/user/spark/applicationHistory
                    --conf
                    spark.yarn.historyServer.address=http://vtqaana-cloudera01.dealer.ddc:18088
                    --conf
                    spark.yarn.am.extraLibraryPath=/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
                    --conf
                    spark.executor.extraLibraryPath=/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/hadoop/lib/native
                    --conf
                    spark.yarn.jar=local:/opt/cloudera/parcels/CDH-5.4.1-1.cdh5.4.1.p0.6/lib/spark/assembly/lib/spark-assembly-1.3.0-cdh5.4.1-hadoop2.6.0-cdh5.4.1.jar
                    --conf
                    spark.master=yarn-client
                    --conf
                    spark.shuffle.service.enabled=true
                    --conf
                    spark.shuffle.service.port=7337
                    --num-executors
                    3
                    --verbose
                    hdfs://nameservice1/ad/jars/rtb-spark-viewthrough_2.10.jar
                    -n
                    RTBViewThroughCorrelation
                    --kryoClasses
                    com.dealer.analytics.ad.intake.RTBEnrichedImpression,com.dealer.analytics.pixall.intake.PixAllHit,com.dealer.analytics.ad.intake.RTBImpression
                    --properties
                    mutableOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/mutable/2015-06-11-16,permOutputFileName=hdfs://nameservice1/ad/RTBViewCorrelated/immutable/2015-06-11-16,viewsFile=hdfs://nameservice1/ad/RTBPixallHit/incoming/2015/06/11/16,summarizeTimeUnit=hour,mutableWindowStart=2015-05-12T16:00:00
                    --impressionFiles
                    hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/16,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/15,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/14,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/13,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/12,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/11,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/10,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/09,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/08,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/07,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/06,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/05,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/04,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/03,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/02,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/01,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/11/00,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/23,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/22,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/21,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/20,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/19,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/18,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/17,hdfs://nameservice1/ad/RTBImpression/incoming/2015/06/10/16

=================================================================

>>> Invoking Spark class now >>>

Heart beat
Heart beat
Heart beat
Heart beat

<<< Invocation of Main class completed <<<


Oozie Launcher ends